import yt_dlp
import ffmpeg
import os
from celery import Celery
from telegram.ext import ExtBot
from functools import wraps 
import subprocess
import telegram 
import shlex 
import sys
import shutil
import tempfile
import re
import logging
import asyncio
import json
import urllib.parse
import zipfile
import requests
import concurrent.futures
from telegram.error import TimedOut, NetworkError
from datetime import datetime, timedelta
from pathlib import Path
from bs4 import BeautifulSoup
from typing import Tuple, List, Dict
from urllib.parse import urljoin
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.firefox.service import Service as FirefoxService
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from webdriver_manager.firefox import GeckoDriverManager
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    ConversationHandler,
    filters,
)
from telethon import TelegramClient
from telethon.sessions import StringSession
from telethon.errors import FloodWaitError
from telethon.tl.functions.channels import CreateChannelRequest, EditAdminRequest
from telethon.tl.types import ChatAdminRights, PeerChannel 


BOT_TOKEN = "8028761324:AAG9w1-MujBb7b2hlGvrIQU3MeIVtDXIkAw" 


API_ID = 22258582
API_HASH = "fefb9d648559a97bf26726d08be33bd4"
SESSION_STRING = "1BVtsOIsBu8OvljNYtlZFa_kc5di7w8qFGQgllt3BzoeLu_7zNE29pjCzps1mUBCyPNNgg9mw9_acllZx03jxgWXwArpf1b6UiqFoBHGF1BKPPxT8QwhjMuO2OUdl60ghsun9Yy96n1Fy-fE89CCvG8o_9iSyc8cG5G5VSgk5zzQtcreUdGY0V-aSdDC1gsB46gL5QLJ95JnU5y4nrKF1y6rWmWgmfqiQkI7cJP-z9fYQ23GmiWkNCce1fnJQKZDdR4VdE38ht2cO3Uy5Qi67XQBiEtOkhizfjBRbQdVXzX_2vHeviLUbeCYrT1XrOTp9vOQvDGK90-lQ4qWxdACcu-j8FQ1cAxA="
PUBLIC_ARCHIVE_CHAT_ID = -1003060382151
VIDEO_CACHE_DB = "VideoCache.json"

BOT_USERNAME = "OviaRobot" 

FONT_FILE = "Aviny.ttf" 
WATERMARK_DB = "WatermarkSettings.json"

TEXTS_DB_FILE = "texts.json"

ADMIN_IDS = [7922716668, 1231355433] 
USER_DB_FILE = "BotData.json"

RETRY_PARAMS = {
    'autoretry_for': (TimedOut, NetworkError),

    'retry_kwargs': {'max_retries': 3},

    'retry_backoff': True,

    'retry_backoff_max': 600,

    'retry_jitter': True
}


COOLDOWN_SECONDS = 60

DOWNLOAD_FOLDER = "Downloads"
COOKIES_CONFIG = None

GALLERY_DL_SITES = ["rule34.xyz", "coomer.st", "aryion.com", "kemono.cr", "tapas.io", "tsumino.com", "danbooru.donmai.us", "e621.net"]

GALLERY_DL_ZIP_SITES = ["mangadex.org", "e-hentai.org"]

TOONILY_COM_DOMAIN = "toonily.com"
TOONILY_ME_DOMAIN = "toonily.me"
MANHWACLAN_DOMAIN = "manhwaclan.com"
MANGA_DISTRICT_DOMAIN = "mangadistrict.com"
COSPLAYTELE_DOMAIN = "cosplaytele.com" 
COMICK_DOMAIN = "comick.io"
PORNHUB_DOMAIN = "pornhub.com"
EROME_DOMAIN = "erome.com"
EPORNER_DOMAIN = "eporner.com"
XVIDEOS_DOMAIN = "xvideos.com"

THUMBNAIL_DB = "Thumb.json"
SET_THUMBNAIL_TEXT = "ğŸ–¼ï¸ ØªÙ†Ø¸ÛŒÙ… ØªØ§Ù…Ø¨Ù†ÛŒÙ„"

ALL_SUPPORTED_SITES = {
    "Manhwa/Webtoon": [TOONILY_COM_DOMAIN, TOONILY_ME_DOMAIN, MANHWACLAN_DOMAIN, MANGA_DISTRICT_DOMAIN, COMICK_DOMAIN],
    "Gallery/Hentai": GALLERY_DL_SITES + GALLERY_DL_ZIP_SITES,
    "Album": [EROME_DOMAIN],
    "Cosplay": [COSPLAYTELE_DOMAIN],
    "Video": [PORNHUB_DOMAIN, EPORNER_DOMAIN, XVIDEOS_DOMAIN]
}



logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

AWAIT_THUMBNAIL = 0

COM_SELECTING_CHAPTERS, COM_AWAIT_ZIP_OPTION = range(1, 3)
ME_AWAIT_MANHWA_SEARCH, ME_SELECTING_MANHWA, ME_SELECTING_CHAPTERS, ME_AWAIT_ZIP_OPTION = range(3, 7)
MC_SELECTING_CHAPTERS, MC_AWAIT_ZIP_OPTION = range(7, 9)
MD_SELECTING_CHAPTERS, MD_AWAIT_ZIP_OPTION = range(9, 11)
CT_AWAIT_USER_CHOICE = 11
CM_SELECTING_CHAPTERS, CM_AWAIT_ZIP_OPTION = range(12, 14)
GALLERY_DL_AWAIT_ZIP_OPTION = 15
EROME_AWAIT_CHOICE = 16
ADMIN_PANEL, AWAIT_BROADCAST_MESSAGE, AWAIT_BROADCAST_FORWARD, AWAIT_SUB_USER_ID, MANAGE_USER_SUB = range(20, 25)
TEXTS_PANEL, AWAIT_HELP_TEXT = range(25, 27)
WATERMARK_PANEL, AWAIT_WATERMARK_TEXT, AWAIT_WATERMARK_SIZE, AWAIT_WATERMARK_COLOR, AWAIT_WATERMARK_STROKE = range(30, 35)
VIDEO_EDIT, AWAIT_VIDEO_CHOICE = range(40, 42)

def load_db():
    try:
        with open(THUMBNAIL_DB, 'r') as f: return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError): return {}
def save_db(data):
    with open(THUMBNAIL_DB, 'w') as f: json.dump(data, f, indent=4)
def set_user_thumbnail(user_id, file_id):
    db = load_db()
    db[str(user_id)] = file_id
    save_db(db)
def get_user_thumbnail(user_id):
    db = load_db()
    return db.get(str(user_id))
def delete_user_thumbnail(user_id):
    db = load_db()
    if str(user_id) in db:
        del db[str(user_id)]
        save_db(db)
        return True
    return False


def load_user_db():
    """Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„ JSON Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        with open(USER_DB_FILE, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def save_user_db(data):
    """Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ JSON Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    with open(USER_DB_FILE, 'w') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def get_user_data(user_id):
    """[ØªØ§Ø¨Ø¹ ÙˆÛŒØ±Ø§ÛŒØ´ Ø´Ø¯Ù‡] Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ú©Ø±Ø¯Ù‡ Ùˆ ÙÛŒÙ„Ø¯ Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ù†Ø§Ù„ Ø´Ø®ØµÛŒ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    db = load_user_db()
    user_id_str = str(user_id)
    made_change = False
    if user_id_str not in db:
        # Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯
        db[user_id_str] = {
            "username": "",
            "is_admin": user_id in ADMIN_IDS,
            "subscription": {
                "is_active": False,
                "expiry_date": None,
                "allowed_sites": {site: False for category in ALL_SUPPORTED_SITES.values() for site in category},
                "download_limit": -1
            },
            "stats": {
                "last_seen": str(datetime.now()),
                "downloads_today": {"date": str(datetime.now().date()), "count": 0},
                "site_usage": {}
            },

            "personal_archive_id": None
        }
        made_change = True
    
    user_profile = db[user_id_str]
   
    if 'personal_archive_id' not in user_profile:
        user_profile['personal_archive_id'] = None
        made_change = True

    
    if 'download_limit' not in user_profile.get('subscription', {}):
        user_profile.setdefault('subscription', {})['download_limit'] = -1
        made_change = True
    if 'count' not in user_profile.get('stats', {}).get('downloads_today', {}):
         user_profile.setdefault('stats', {}).setdefault('downloads_today', {})['count'] = 0
         made_change = True

    if made_change:
        save_user_db(db)
        
    return db[user_id_str]

def update_user_data(user_id, data):
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    db = load_user_db()
    db[str(user_id)] = data
    save_user_db(db)



def load_texts_db():
    """Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ÙˆÛŒØ±Ø§ÛŒØ´ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        with open(TEXTS_DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        
        return {"help_text": "Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶. Ø§Ø¯Ù…ÛŒÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§ÛŒÙ† Ù…ØªÙ† Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡Ø¯."}

def save_texts_db(data):
    """Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ØªÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    with open(TEXTS_DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

async def show_help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    texts_db = load_texts_db()
    help_text = texts_db.get("help_text", "Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ù‡Ù†ÙˆØ² ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
    await update.message.reply_text(help_text)

async def texts_panel_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø±Ø¨Ø§Øª Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ù…ÛŒÙ† Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."""
    keyboard = [
        [InlineKeyboardButton("ÙˆÛŒØ±Ø§ÛŒØ´ Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§", callback_data="texts_edit_help")],
        [InlineKeyboardButton("Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†", callback_data="texts_back_to_admin")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("Ú©Ø¯Ø§Ù… Ù…ØªÙ† Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯ØŸ", reply_markup=reply_markup)
    return TEXTS_PANEL

async def texts_panel_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ØªÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    query = update.callback_query
    await query.answer()
    data = query.data

    if data == "texts_edit_help":
        await query.message.edit_text("Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø¬Ø¯ÛŒØ¯ Ø±Ø§Ù‡Ù†Ù…Ø§ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ù„ØºÙˆ /cancel Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯.")
        return AWAIT_HELP_TEXT
    
    if data == "texts_back_to_admin":
        await query.message.delete()
      
        return await admin_command(update, context)

    return TEXTS_PANEL

async def await_help_text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù…ØªÙ† Ø¬Ø¯ÛŒØ¯ Ø±Ø§Ù‡Ù†Ù…Ø§ Ø±Ø§ Ø§Ø² Ø§Ø¯Ù…ÛŒÙ† Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    new_text = update.message.text
    texts_db = load_texts_db()
    texts_db["help_text"] = new_text
    save_texts_db(texts_db)

    await update.message.reply_text("âœ… Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯.")
    
    return await texts_panel_command(update, context)


async def get_or_create_personal_archive(user_id: int) -> int | None:
    """
    Ø¢ÛŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø¢Ø±Ø´ÛŒÙˆ Ø´Ø®ØµÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ
    ÛŒÚ© Ú©Ø§Ù†Ø§Ù„ Ø¬Ø¯ÛŒØ¯ Ø®ØµÙˆØµÛŒ Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯ØŒ Ø±Ø¨Ø§Øª Ø±Ø§ Ø§Ø¯Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¢ÛŒØ¯ÛŒ Ø¢Ù† Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    user_data = get_user_data(user_id)
    archive_id = user_data.get("personal_archive_id")
    if archive_id:
        logger.info(f"[Archive] Ú©Ø§Ù†Ø§Ù„ Ø´Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯: {archive_id}")
        return archive_id

    logger.info(f"[Archive] Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ú©Ø§Ù†Ø§Ù„ Ø¢Ø±Ø´ÛŒÙˆ Ø´Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id}...")
    client = TelegramClient(StringSession(SESSION_STRING), API_ID, API_HASH)
    try:
        await client.connect()
        
        result = await client(CreateChannelRequest(
            title=str(user_id),
            about=f"Personal Archive for @{BOT_USERNAME}",
            megagroup=False
        ))
        
        new_channel_id = result.chats[0].id
        full_channel_id = int(f"-100{new_channel_id}")
        
        channel_entity = await client.get_entity(PeerChannel(new_channel_id))
        
        bot_entity = await client.get_entity(BOT_USERNAME)
        admin_rights = ChatAdminRights(
            post_messages=True, edit_messages=True, delete_messages=True,
            invite_users=True, change_info=True, pin_messages=True,
            add_admins=False, ban_users=True, manage_call=True, anonymous=False, other=True
        )
        await client(EditAdminRequest(channel=channel_entity, user_id=bot_entity, admin_rights=admin_rights, rank='bot'))
        
        user_data["personal_archive_id"] = full_channel_id
        update_user_data(user_id, user_data)
        
        logger.info(f"[Archive] Ú©Ø§Ù†Ø§Ù„ Ø´Ø®ØµÛŒ {full_channel_id} Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
        return full_channel_id

    except FloodWaitError as e:
        logger.error(f"[Archive] Flood wait error: Wait for {e.seconds} seconds.")
        await asyncio.sleep(e.seconds)
        return None  # ÛŒØ§ retry Ú©Ù†
    except Exception as e:
        logger.error(f"[Archive] Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú©Ø§Ù†Ø§Ù„ Ø´Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}", exc_info=True)
        return None
    finally:
        if client.is_connected():
            await client.disconnect()

def load_video_cache():
    """Ú©Ø´ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„ JSON Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        with open(VIDEO_CACHE_DB, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def save_video_cache(data):
    """Ú©Ø´ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ JSON Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    with open(VIDEO_CACHE_DB, 'w') as f:
        json.dump(data, f, indent=4)

def add_to_video_cache(url: str, format_id: str, message_id: int):
    """ÛŒÚ© ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ù…Ø´Ø®Øµ Ø±Ø§ Ø¨Ù‡ Ú©Ø´ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    cache = load_video_cache()
    if url not in cache:
        cache[url] = {}
    cache[url][format_id] = message_id
    save_video_cache(cache)
    logger.info(f"[Cache] ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ Ù„ÛŒÙ†Ú© {url} Ùˆ Ú©ÛŒÙÛŒØª {format_id} Ø¨Ù‡ Ú©Ø´ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

def get_from_video_cache(url: str, format_id: str) -> int | None:
    """ÛŒÚ© ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ù…Ø´Ø®Øµ Ø±Ø§ Ø§Ø² Ú©Ø´ Ø¬Ø³ØªØ¬Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    cache = load_video_cache()
    url_cache = cache.get(url)
    
    if isinstance(url_cache, dict):
        return url_cache.get(format_id)
    
    return None

def log_download_activity(user_id, site_domain):
    """ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø± Ø«Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    user_data = get_user_data(user_id)
    today_str = str(datetime.now().date())
    
    if user_data['stats']['downloads_today'].get('date') != today_str:
        user_data['stats']['downloads_today'] = {"date": today_str, "count": 0}
    
    user_data['stats']['downloads_today']['count'] += 1
    user_data['stats']['site_usage'][site_domain] = user_data['stats']['site_usage'].get(site_domain, 0) + 1
    
    update_user_data(user_id, user_data)


def load_watermark_db():
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„ JSON Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        with open(WATERMARK_DB, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def save_watermark_db(data):
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ JSON Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    with open(WATERMARK_DB, 'w') as f:
        json.dump(data, f, indent=4)

def get_user_watermark_settings(user_id: int) -> dict:
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ÛŒØ§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯."""
    db = load_watermark_db()
    user_id_str = str(user_id)
    if user_id_str in db:
        
        defaults = {
            "enabled": False,
            "text": f"@{BOT_USERNAME}",
            "position": "top_left",
            "size": 32,
            "color": "white",
            "stroke": 2,
        }
        
        user_settings = db[user_id_str]
        for key, value in defaults.items():
            user_settings.setdefault(key, value)
        return user_settings
    else:
        
        return {
            "enabled": False,
            "text": f"@{BOT_USERNAME}",
            "position": "top_left",
            "size": 32,
            "color": "white",
            "stroke": 2,
        }

def update_user_watermark_settings(user_id: int, new_settings: dict):
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    db = load_watermark_db()
    db[str(user_id)] = new_settings
    save_watermark_db(db)


def cooldown_decorator(seconds=COOLDOWN_SECONDS):
    """
    Decorator to enforce a cooldown on users for starting new download processes.
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
            user_id = update.effective_user.id
            
            
            if user_id in ADMIN_IDS:
                return await func(update, context, *args, **kwargs)

            if 'user_cooldowns' not in context.bot_data:
                context.bot_data['user_cooldowns'] = {}

            last_call_time = context.bot_data['user_cooldowns'].get(user_id)

            if last_call_time:
                time_passed = datetime.now() - last_call_time
                if time_passed.total_seconds() < seconds:
                    remaining_time = seconds - time_passed.total_seconds()
                    message_to_send = f"Ù„Ø·ÙØ§Ù‹ Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒØ¯. Ø´Ù…Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªØ§ {int(remaining_time)} Ø«Ø§Ù†ÛŒÙ‡ Ø¯ÛŒÚ¯Ø± Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ù‡ÛŒØ¯."
                    
                    if update.callback_query:
                        await update.callback_query.answer(text=message_to_send, show_alert=True)
                    else:
                        await update.message.reply_text(message_to_send)
                    return
            
            result = await func(update, context, *args, **kwargs)
            
            if result is not None and result != ConversationHandler.END:
                 context.bot_data['user_cooldowns'][user_id] = datetime.now()

            return result
        return wrapper
    return decorator


REDIS_URL = "redis://localhost:6379/0"
celery_app = Celery('bot_tasks', broker=REDIS_URL, backend=REDIS_URL)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    
    broker_connection_retry_on_startup=True,
)


def get_bot_instance():
    """
    ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ ExtBot Ø¨Ø±Ø§ÛŒ ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Celery Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¨Ù‡ Ø³Ø±ÙˆØ± API Ù…Ø­Ù„ÛŒ Ù…ØªØµÙ„ Ø§Ø³Øª.
    """
    
    return ExtBot(
        token=BOT_TOKEN,
        base_url="http://91.107.146.233:8081/bot",
        base_file_url="http://91.107.146.233:8081/file/bot"
    )


async def check_subscription(user_id: int, domain: str) -> Tuple[bool, str]:
    """
    [Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø§ Ù…Ù†Ø·Ù‚ Whitelist]
    ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø§Ø´ØªØ±Ø§Ú© Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø³ØªØ±Ø³ÛŒ ØªÙ†Ù‡Ø§ Ø¯Ø± ØµÙˆØ±ØªÛŒ Ù…Ø¬Ø§Ø² Ø§Ø³Øª Ú©Ù‡
    Ø§Ø´ØªØ±Ø§Ú© ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù‡ Ùˆ Ø³Ø§ÛŒØª Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ù‡ ØµØ±Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± ÙØ¹Ø§Ù„ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.
    """
    user_data = get_user_data(user_id)
    if user_data.get('is_admin', False):
        return True, "Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø¯Ù…ÛŒÙ† ØªØ§ÛŒÛŒØ¯ Ø´Ø¯."

    sub = user_data.get('subscription', {})
    
    
    if not sub.get('is_active', False):
        return False, "Ø§Ø´ØªØ±Ø§Ú© Ø´Ù…Ø§ ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ø¨Ø§ØªØŒ Ø§Ø´ØªØ±Ø§Ú© ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯."

    
    expiry_date_str = sub.get('expiry_date')
    if expiry_date_str:
        try:
            if datetime.fromisoformat(expiry_date_str) < datetime.now():
                user_data['subscription']['is_active'] = False
                update_user_data(user_id, user_data)
                return False, "Ø§Ø´ØªØ±Ø§Ú© Ø´Ù…Ø§ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ ØªÙ…Ø¯ÛŒØ¯ Ú©Ù†ÛŒØ¯."
        except (ValueError, TypeError):
            user_data['subscription']['is_active'] = False
            update_user_data(user_id, user_data)
            return False, "Ø®Ø·Ø§ Ø¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø´ØªØ±Ø§Ú©. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯."


    limit = sub.get('download_limit', -1)
    if limit != -1:
        stats = user_data.get('stats', {})
        downloads_today_data = stats.get('downloads_today', {})
        today_str = str(datetime.now().date())
        
        downloads_today_count = downloads_today_data.get('count', 0) if downloads_today_data.get('date') == today_str else 0
        if downloads_today_count >= limit:
            return False, f"Ø´Ù…Ø§ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø®ÙˆØ¯ ({limit} ÙØ§ÛŒÙ„) Ø±Ø³ÛŒØ¯Ù‡â€ŒØ§ÛŒØ¯."


    if sub.get('allowed_sites', {}).get(domain, False):
        
        return True, "Ø¯Ø³ØªØ±Ø³ÛŒ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯."
    else:
       
        return False, "Ø§ÛŒÙ† ÙˆØ¨Ø³Ø§ÛŒØª Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª."


async def manage_subscription(update: Update, context: ContextTypes.DEFAULT_TYPE, is_recall: bool = False, user_id_override: int = None) -> int:
    """[Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ] Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø´ØªØ±Ø§Ú© Ø¨Ø§ Ø¯Ú©Ù…Ù‡ ÙØ¹Ø§Ù„/ØºÛŒØ±ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù‡Ù…Ù‡ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§."""
    try:
        target_user_id = user_id_override if is_recall else int(update.message.text)
    except (ValueError, TypeError):
        await update.message.reply_text("Invalid User ID. Please enter a number.")
        return AWAIT_SUB_USER_ID

    context.user_data['target_user_id'] = target_user_id
    user_data = get_user_data(target_user_id)
    if not isinstance(user_data, dict):
        await update.message.reply_text("Error: User data is corrupted.")
        return ADMIN_PANEL

    sub = user_data.get('subscription', {})
    username = user_data.get('username') or "N/A"
    
    expiry_date_str = sub.get('expiry_date')
    remain_days = "Unlimited"
    if expiry_date_str:
        try:
            delta = datetime.fromisoformat(expiry_date_str) - datetime.now()
            remain_days = max(0, delta.days)
        except (ValueError, TypeError):
            remain_days = "Invalid"

    limit = sub.get('download_limit', -1)
    limit_text = "Unlimited" if limit == -1 else str(limit)

    sub_info_text = (
        f"ğŸ‘¤ @{username}\n"
        f"â€¢ UID: {target_user_id}\n"
        f"â€¢ Remainday: {remain_days}\n"
        f"â€¢ Limit: {limit_text}/day"
    )

    keyboard = []
    
    status_text = "ACTIVE âœ…" if sub.get('is_active') else "DEACTIVATED âŒ"
    keyboard.append([InlineKeyboardButton(status_text, callback_data="sub_toggle_active")])

    all_sites_flat = [site for category_sites in ALL_SUPPORTED_SITES.values() for site in category_sites]
    
    
    all_sites_active = all(sub.get('allowed_sites', {}).get(site) for site in all_sites_flat)
    
    row = []
    for site in all_sites_flat:
        site_status = "â˜‘ï¸" if sub.get('allowed_sites', {}).get(site) else "âœ–ï¸"
        row.append(InlineKeyboardButton(f"{site} {site_status}", callback_data=f"sub_toggle_site_{site}"))
        if len(row) == 2:
            keyboard.append(row)
            row = []
    if row:
        keyboard.append(row)

    
    if all_sites_active:
        keyboard.append([InlineKeyboardButton("Deactivate All Sites", callback_data="sub_deactivate_all_sites")])
    else:
        keyboard.append([InlineKeyboardButton("Activate All Sites", callback_data="sub_activate_all_sites")])
    

    time_button_text = f"{remain_days} days left" if isinstance(remain_days, int) else "no time set"
    time_row = [
        InlineKeyboardButton("-10", callback_data="sub_rem_days_10"),
        InlineKeyboardButton(time_button_text, callback_data="sub_noop"),
        InlineKeyboardButton("+10", callback_data="sub_add_days_10")
    ]
    keyboard.append(time_row)

    limit_button_text = f"{limit_text} per day" if limit != -1 else "no limit"
    limit_row = [
        InlineKeyboardButton("-10", callback_data="sub_rem_limit_10"),
        InlineKeyboardButton(limit_button_text, callback_data="sub_noop"),
        InlineKeyboardButton("+10", callback_data="sub_add_limit_10")
    ]
    keyboard.append(limit_row)
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    message_to_use = update.callback_query.message if is_recall and update.callback_query else update.message
    
    if is_recall:
        try:
            await message_to_use.edit_text(sub_info_text, reply_markup=reply_markup)
        except telegram.error.BadRequest as e:
            if "Message is not modified" in str(e):
                pass
            else:
                raise
    else:
        await message_to_use.reply_text(sub_info_text, reply_markup=reply_markup)
        
    return MANAGE_USER_SUB

async def manage_subscription_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    [Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ù¾Ø§Ø³Ø® Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ù„ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø´ØªØ±Ø§Ú© Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    query = update.callback_query
    await query.answer()
    data = query.data
    
    target_user_id = context.user_data.get('target_user_id')
    if not target_user_id:
        await query.edit_message_text("Error: User session expired. Please try again.")
        return ADMIN_PANEL

    user_data = get_user_data(target_user_id)
    sub = user_data['subscription']

    if data.startswith("sub_toggle_site_"):
        site = data.replace("sub_toggle_site_", "")
        sub['allowed_sites'][site] = not sub['allowed_sites'].get(site, False)
    
    
    elif data == "sub_activate_all_sites":
        all_sites_flat = [site for category_sites in ALL_SUPPORTED_SITES.values() for site in category_sites]
        for site in all_sites_flat:
            sub['allowed_sites'][site] = True
    elif data == "sub_deactivate_all_sites":
        all_sites_flat = [site for category_sites in ALL_SUPPORTED_SITES.values() for site in category_sites]
        for site in all_sites_flat:
            sub['allowed_sites'][site] = False
  

    elif data == "sub_toggle_active":
        sub['is_active'] = not sub['is_active']

    elif data.startswith("sub_add_days_"):
        days_to_add = int(data.split('_')[-1])
        current_expiry_str = sub.get('expiry_date')
        base_time = datetime.now()
        if current_expiry_str:
            try:
                current_expiry = datetime.fromisoformat(current_expiry_str)
                if current_expiry > base_time:
                    base_time = current_expiry
            except (ValueError, TypeError):
                pass
        sub['expiry_date'] = str(base_time + timedelta(days=days_to_add))

    elif data.startswith("sub_rem_days_"):
        days_to_rem = int(data.split('_')[-1])
        current_expiry_str = sub.get('expiry_date')
        if current_expiry_str:
            try:
                new_expiry = datetime.fromisoformat(current_expiry_str) - timedelta(days=days_to_rem)
                sub['expiry_date'] = str(max(datetime.now(), new_expiry))
            except (ValueError, TypeError):
                sub['expiry_date'] = None

    elif data.startswith("sub_add_limit_"):
        limit_to_add = int(data.split('_')[-1])
        current_limit = sub.get('download_limit', -1)
        sub['download_limit'] = limit_to_add if current_limit == -1 else current_limit + limit_to_add
            
    elif data.startswith("sub_rem_limit_"):
        limit_to_rem = int(data.split('_')[-1])
        current_limit = sub.get('download_limit', -1)
        if current_limit != -1:
            sub['download_limit'] -= limit_to_rem
            if sub['download_limit'] <= 0:
                sub['download_limit'] = -1
        
    elif data == "sub_noop":
        return MANAGE_USER_SUB

    update_user_data(target_user_id, user_data)
    await manage_subscription(update, context, is_recall=True, user_id_override=target_user_id)
    return MANAGE_USER_SUB


async def admin_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†."""
    user_id = update.effective_user.id
    if user_id not in ADMIN_IDS:
        await update.message.reply_text("Ø´Ù…Ø§ Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return ConversationHandler.END

    keyboard = [
        ["ğŸ“Š Ø¢Ù…Ø§Ø±", "ğŸ“¢ Ù‡Ù…Ú¯Ø§Ù†ÛŒ"],
        ["âš™ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø´ØªØ±Ø§Ú©"],
        ["âŒ Ø®Ø±ÙˆØ¬ Ø§Ø² Ù¾Ù†Ù„"]
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    await update.message.reply_text("Ø¨Ù‡ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ† Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.", reply_markup=reply_markup)
    return ADMIN_PANEL

def check_dependencies():
    """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±Ù‡Ø§."""
    all_ok = True
    if not shutil.which("ffmpeg"):
        logger.error("ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒ `ffmpeg` ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        all_ok = False
    if not shutil.which("gallery-dl"):
        logger.error("ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒ `gallery-dl` ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ `pip install gallery-dl` Ø¢Ù† Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯.")
        all_ok = False
    try:
        ChromeDriverManager().install()
        logger.info("[Selenium] âœ“ Ø¯Ø±Ø§ÛŒÙˆØ± Chrome Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯.")
    except Exception as e:
        logger.error(f"[Selenium] âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ… WebDriver. Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Chrome Ù†ØµØ¨ Ø§Ø³Øª. Ø®Ø·Ø§: {e}")
        all_ok = False
        
    if all_ok:
        logger.info("ØªÙ…Ø§Ù… ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù†Ø¯.")
    return all_ok

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ ---
def sanitize_filename(name: str) -> str:
    """Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… ÙØ§ÛŒÙ„ ÛŒØ§ Ù¾ÙˆØ´Ù‡ Ø±Ø§ Ø­Ø°Ù ÛŒØ§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    return re.sub(r'[\\/*?:"<>|]', "-", name).strip()

def create_zip_from_folder(folder_path: str, zip_output_path: str):
    """ÛŒÚ© Ù¾ÙˆØ´Ù‡ Ø±Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„ ZIP ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    with zipfile.ZipFile(zip_output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, _, files in os.walk(folder_path):
            for file in sorted(files):
                full_path = os.path.join(root, file)
                relative_path = os.path.relpath(full_path, os.path.dirname(folder_path))
                zipf.write(full_path, relative_path)


def get_full_video_info(url):
    logger.info(f"[yt-dlp] Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú©: {url}")
    ydl_opts = {'quiet': True, 'no_warnings': True, 'cookiesfrombrowser': COOKIES_CONFIG} if COOKIES_CONFIG else {'quiet': True, 'no_warnings': True}
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl: return ydl.extract_info(url, download=False)
    except Exception as e:
        logger.error(f"[yt-dlp] Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯ÛŒÙˆ: {e}"); return None
    
def download_video(url, temp_dir, format_id):
    temp_filename = os.path.join(temp_dir, 'initial_download')
    ydl_opts = {'format': format_id, 'outtmpl': temp_filename, 'quiet': False, 'no_warnings': True, 'ignoreerrors': False, 'progress': True}
    if COOKIES_CONFIG: ydl_opts['cookiesfrombrowser'] = COOKIES_CONFIG
    logger.info(f"[yt-dlp] Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ø² {url} Ø¨Ø§ Ú©ÛŒÙÛŒØª '{format_id}'")
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl: ydl.download([url])
        actual_file = next((os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.startswith('initial_download')), None)
        if not actual_file: raise FileNotFoundError("ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· yt-dlp ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return actual_file
    except Exception as e:
        logger.error(f"[yt-dlp] Ø®Ø·Ø§ Ø¯Ø± Ø­ÛŒÙ† Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§ÙˆÙ„ÛŒÙ‡: {e}"); return None
    
def repair_video(initial_path, repaired_path):
    logger.info("[yt-dlp] Ø´Ø±ÙˆØ¹ ØªØ¹Ù…ÛŒØ± Ùˆ Ú©Ù¾ÛŒ Ø§Ø³ØªØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ...")
    try:
        ffmpeg.input(initial_path).output(repaired_path, c='copy', loglevel='error').run(overwrite_output=True)
        return True
    except ffmpeg.Error as e:
        logger.error(f"[yt-dlp] Ø®Ø·Ø§ÛŒ ffmpeg Ø¯Ø± Ø­ÛŒÙ† Ú©Ù¾ÛŒ Ø§Ø³ØªØ±ÛŒÙ…: {e.stderr.decode()}"); return False
    
def verify_and_finalize(repaired_path, final_output_path):
    logger.info("[yt-dlp] Ø´Ø±ÙˆØ¹ ØªØ£ÛŒÛŒØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ...")
    try:
        probe = ffmpeg.probe(repaired_path)
        duration = float(probe.get('format', {}).get('duration', 0))
        if duration > 0:
            os.makedirs(os.path.dirname(final_output_path), exist_ok=True)
            shutil.move(repaired_path, final_output_path)
            return final_output_path
        return None
    except (ffmpeg.Error, ValueError) as e:
        logger.error(f"[yt-dlp] Ø®Ø·Ø§ Ø¯Ø± Ø­ÛŒÙ† ØªØ£ÛŒÛŒØ¯ ÙØ§ÛŒÙ„: {e}"); return None


@celery_app.task(name="tasks.process_video_customization")
def process_video_customization_task(user_id: int, chat_id: int, personal_archive_id: int, video_file_id: str, choice: str):
    """
    [Ù†Ø³Ø®Ù‡ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª ÙˆØ§Ø­Ø¯]
    ÛŒÚ© ØªØ³Ú© Celery Ú©Ù‡ ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ØŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø±Ø§ Ø¯Ø± ÛŒÚ© Ù¾ÛŒØ§Ù… ÙˆØ§Ø­Ø¯ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = None  
        
        with tempfile.TemporaryDirectory() as temp_dir:
            try:
                
                status_message = await bot.send_message(chat_id=chat_id, text="â³ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø´Ù…Ø§ Ø´Ø±ÙˆØ¹ Ø´Ø¯...")
                message_id_to_edit = status_message.message_id

                
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø§ØµÙ„ÛŒ...")
                video_file = await bot.get_file(video_file_id)
                video_path = os.path.join(temp_dir, 'original_video.mp4')
                await video_file.download_to_drive(custom_path=video_path)
                logger.info(f"ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ file_id: {video_file_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ù…Ø³ÛŒØ± {video_path} Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯.")

                
                final_video_path = video_path
                custom_thumb_path = None
                
                if choice in ['water', 'both']:
                    await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ’§ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú©...")
                    watermark_settings = get_user_watermark_settings(user_id)
                    final_video_path = await asyncio.to_thread(
                        apply_watermark_to_video, video_path, watermark_settings
                    )
                    if not final_video_path:
                        raise Exception("Ø§Ø¹Ù…Ø§Ù„ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
                
                if choice in ['thumb', 'both']:
                    custom_thumbnail_id = get_user_thumbnail(user_id)
                    if custom_thumbnail_id:
                        await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ–¼ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ§Ù…Ø¨Ù†ÛŒÙ„...")
                        thumb_file = await bot.get_file(custom_thumbnail_id)
                        custom_thumb_path = os.path.join(temp_dir, 'thumb.jpg')
                        await thumb_file.download_to_drive(custom_path=custom_thumb_path)

                
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")
                duration, width, height = await asyncio.to_thread(get_video_metadata, final_video_path)
                
                uploaded_message_id = await upload_video_with_bot_api(
                    bot=bot,
                    target_chat_id=personal_archive_id,
                    file_path=final_video_path,
                    thumb_path=custom_thumb_path,
                    caption=f"Edited for {user_id}",
                    duration=duration, width=width, height=height
                )
                if not uploaded_message_id:
                    raise Exception("Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")

                
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="âœ… ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø´Ù…Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª! Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„...")
                await bot.copy_message(
                    chat_id=chat_id,
                    from_chat_id=personal_archive_id,
                    message_id=uploaded_message_id
                )
                
                
                await bot.delete_message(chat_id=chat_id, message_id=message_id_to_edit)

            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Ú© Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}", exc_info=True)
                
                if status_message:
                     await bot.edit_message_text(chat_id=chat_id, message_id=status_message.message_id, text=f"âŒ Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø´Ù…Ø§ Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯:\n`{e}`")
                
                else:
                     await bot.send_message(chat_id=chat_id, text=f"âŒ Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø´Ù…Ø§ Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯:\n`{e}`")

    asyncio.run(_async_worker())


async def handle_user_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    [Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ]
    ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ø´Ø®ØµÛŒ Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù‡ Ùˆ file_id Ø¢Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ³Ú© Celery Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    user = update.effective_user
    if not update.message or not update.message.video:
        return ConversationHandler.END

    message = await update.message.reply_text("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆ...")
    
    personal_archive_id = await get_or_create_personal_archive(user.id)
    if not personal_archive_id:
        await message.edit_text("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ Ø¢Ø±Ø´ÛŒÙˆ Ø´Ù…Ø§. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        return ConversationHandler.END

    try:
       
        video_file_id = update.message.video.file_id
        context.user_data['video_to_edit_file_id'] = video_file_id
        
        
        await context.bot.copy_message(
            chat_id=personal_archive_id,
            from_chat_id=update.message.chat_id,
            message_id=update.message.message_id
        )
        
        logger.info(f"ÙˆÛŒØ¯ÛŒÙˆ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± {user.id} Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ {personal_archive_id} Ú©Ù¾ÛŒ Ø´Ø¯. File ID: {video_file_id}")

    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ú©Ù¾ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ Ø´Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user.id}: {e}")
        await message.edit_text("Ø®Ø·Ø§ Ø¯Ø± Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø´Ù…Ø§.")
        return ConversationHandler.END

    keyboard = [
        [InlineKeyboardButton("ğŸ–¼ï¸ ØªÙ†Ø¸ÛŒÙ… ØªØ§Ù…Ø¨Ù†ÛŒÙ„", callback_data="vid_edit_thumb")],
        [InlineKeyboardButton("ğŸ’§ ØªÙ†Ø¸ÛŒÙ… ÙˆØ§ØªØ±Ù…Ø§Ø±Ú©", callback_data="vid_edit_water")],
        [InlineKeyboardButton("ğŸ–¼ï¸ğŸ’§ ØªÙ†Ø¸ÛŒÙ… Ù‡Ø± Ø¯Ùˆ", callback_data="vid_edit_both")],
        [InlineKeyboardButton("âŒ Ù„ØºÙˆ", callback_data="vid_edit_cancel")],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.edit_text("Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ø§ Ø§ÛŒÙ† ÙˆÛŒØ¯ÛŒÙˆ Ú†Ù‡ Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯ØŸ", reply_markup=reply_markup)

    return AWAIT_VIDEO_CHOICE

async def process_video_edit_choice(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    [Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡]
    Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø±Ø¯Ù‡ Ùˆ ØªØ³Ú© Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø±Ø§ Ø¨Ø§ file_id Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    query = update.callback_query
    await query.answer()
    choice = query.data.replace("vid_edit_", "")

    if choice == 'cancel':
        await query.edit_message_text("Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
        return ConversationHandler.END

    user_id = query.from_user.id
    personal_archive_id = get_user_data(user_id).get("personal_archive_id")
    # --- [ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ] Ø®ÙˆØ§Ù†Ø¯Ù† file_id Ø§Ø² user_data ---
    video_file_id = context.user_data.get('video_to_edit_file_id')

    if not all([personal_archive_id, video_file_id]):
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        return ConversationHandler.END

    await query.edit_message_text("âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ù‡ ØµÙ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯...")

   
    process_video_customization_task.delay(
        user_id=user_id,
        chat_id=query.message.chat_id,
        personal_archive_id=personal_archive_id,
        video_file_id=video_file_id,
        choice=choice
    )
    
    context.user_data.pop('video_to_edit_file_id', None)
    return ConversationHandler.END

async def run_gallery_dl_download(url: str, temp_dir: str):
    logger.info(f"[gallery-dl] Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø²: {url}")
    command = ['gallery-dl', '-D', temp_dir, url]
    process = await asyncio.create_subprocess_exec(*command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
    stdout, stderr = await process.communicate()
    if process.returncode != 0:
        error_message = stderr.decode('utf-8', errors='ignore').strip()
        logger.error(f"[gallery-dl] Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø¯Ø§Ù†Ù„ÙˆØ¯. Ú©Ø¯ Ø®Ø·Ø§: {process.returncode}\n{error_message}")
        return None, error_message
    downloaded_files = [os.path.join(root, file) for root, _, files in os.walk(temp_dir) for file in files]
    return downloaded_files, None


CT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def ct_analyze_and_extract_media(page_url: str) -> Dict[str, List[str]]:
    """
    ØµÙØ­Ù‡ CosplayTele Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ùˆ Ù„ÛŒÙ†Ú© Ù…Ø³ØªÙ‚ÛŒÙ… Ø¹Ú©Ø³â€ŒÙ‡Ø§ Ùˆ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    logger.info(f"[{COSPLAYTELE_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡: {page_url}")
    media_urls = {'images': [], 'videos': []}
    try:
        response = requests.get(page_url, headers=CT_HEADERS, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        
        gallery = soup.find('div', class_='gallery')
        if gallery:
            image_links = gallery.find_all('a', href=re.compile(r'\.(jpg|jpeg|png|gif|webp)$', re.I))
            for link in image_links:
                media_urls['images'].append(urljoin(page_url, link['href']))

        
        video_iframes = soup.find_all('iframe', src=re.compile(r'aparat\.com|youtube\.com|cossora\.stream', re.I))
        for iframe in video_iframes:
            media_urls['videos'].append(iframe['src'])
            
        for video_tag in soup.find_all('video'):
            src = video_tag.get('src')
            if not src:
                source_tag = video_tag.find('source')
                if source_tag:
                    src = source_tag.get('src')
            if src:
                media_urls['videos'].append(urljoin(page_url, src))

        media_urls['images'] = sorted(list(dict.fromkeys(media_urls['images'])))
        media_urls['videos'] = sorted(list(dict.fromkeys(media_urls['videos'])))
        
        logger.info(f"[{COSPLAYTELE_DOMAIN}] {len(media_urls['images'])} Ø¹Ú©Ø³ Ùˆ {len(media_urls['videos'])} ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ÙØª Ø´Ø¯.")
        return media_urls

    except requests.exceptions.RequestException as e:
        logger.error(f"[{COSPLAYTELE_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ØµÙØ­Ù‡: {e}")
        return None
    except Exception as e:
        logger.error(f"[{COSPLAYTELE_DOMAIN}] Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØµÙØ­Ù‡: {e}")
        return None

def ct_download_single_image(args: Tuple[str, str]) -> bool:
    """ÛŒÚ© ØªØµÙˆÛŒØ± Ø±Ø§ Ø§Ø² CosplayTele Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    img_url, file_path = args
    try:
        res = requests.get(img_url, headers=CT_HEADERS, stream=True, timeout=30)
        res.raise_for_status()
        with open(file_path, 'wb') as f:
            for chunk in res.iter_content(chunk_size=8192):
                f.write(chunk)
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"[{COSPLAYTELE_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± {img_url}: {e}")
        return False


def setup_driver():
    logger.info("[Toonily.com] Ø¯Ø± Ø­Ø§Ù„ ØªÙ†Ø¸ÛŒÙ… Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯Ø±Ø§ÛŒÙˆØ± Ù…Ø±ÙˆØ±Ú¯Ø±...")
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--log-level=3")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        logger.info("[Toonily.com] âœ“ Ø¯Ø±Ø§ÛŒÙˆØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯.")
        return driver
    except Exception as e:
        logger.error(f"[Toonily.com] âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯Ø±Ø§ÛŒÙˆØ± Selenium Ø±Ø® Ø¯Ø§Ø¯: {e}")
        return None
def find_all_chapters_com(main_manhwa_url, driver):
    logger.info(f"[Toonily.com] Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§ Ø¯Ø±: {main_manhwa_url}")
    driver.get(main_manhwa_url)
    try:
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "ul.version-chap")))
    except Exception:
        logger.error("[Toonily.com] âŒ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù„ÛŒØ³Øª Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
        return [], None
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    manhwa_title_tag = soup.find('div', class_='post-title')
    manhwa_title = manhwa_title_tag.h1.text.strip() if manhwa_title_tag else "Untitled_Manhwa"
    sanitized_title = sanitize_filename(manhwa_title)
    chapter_list_container = soup.find('ul', class_='version-chap')
    if not chapter_list_container: return [], None
    chapters = [{'title': item.find('a').text.strip(), 'url': item.find('a')['href']} for item in chapter_list_container.find_all('li', class_='wp-manga-chapter') if item.find('a')]
    chapters.reverse()
    logger.info(f"[Toonily.com] âœ“ {len(chapters)} Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ '{sanitized_title}' ÛŒØ§ÙØª Ø´Ø¯.")
    return chapters, sanitized_title
def get_chapter_image_urls_com(chapter_url, driver):
    driver.get(chapter_url)
    try:
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.reading-content img.wp-manga-chapter-img")))
    except Exception: return []
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    reading_container = soup.find('div', class_='reading-content')
    return [img.get('data-src', img.get('src', '')).strip() for img in reading_container.find_all('img', class_='wp-manga-chapter-img') if img.get('data-src') or img.get('src')]
def download_single_image_com(args):
    img_url, file_path = args
    if os.path.exists(file_path): return 'skipped'
    try:
        res = requests.get(img_url, stream=True, timeout=30, headers={'Referer': 'https://toonily.com/'})
        res.raise_for_status()
        with open(file_path, 'wb') as f: shutil.copyfileobj(res.raw, f)
        return 'downloaded'
    except requests.exceptions.RequestException: return 'failed'

def download_images_for_chapter_sync_com(chapter_info, manhwa_folder, manhwa_title, driver):
    """
    (Synchronous and Corrected Version)
    Downloads all images for a single chapter from Toonily.com.
    Uses 'name' key instead of 'title'.
    """

    chapter_title = chapter_info['name'] 
    

    safe_chapter_title = sanitize_filename(chapter_title)
    temp_folder = os.path.join(manhwa_folder, f"{manhwa_title} - {safe_chapter_title}")
    os.makedirs(temp_folder, exist_ok=True)
    
    image_urls = get_chapter_image_urls_com(chapter_info['url'], driver)
    
    if not image_urls:
        logger.warning(f"No image URLs found for chapter '{chapter_title}'")
        return None
        
    tasks = [(url, os.path.join(temp_folder, f"{i+1:03d}{os.path.splitext(urllib.parse.urlparse(url).path)[1] or '.jpg'}")) for i, url in enumerate(image_urls)]
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        list(executor.map(download_single_image_com, tasks))
        
    return temp_folder


MN2_BASE_URL = f"https://{TOONILY_ME_DOMAIN}"
MN2_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0',
    'Accept': 'image/avif,image/webp,*/*',
    'Accept-Language': 'en-US,en;q=0.5',
    'Referer': MN2_BASE_URL + '/',
}
def mn2_search(query: str) -> list[dict]:
    search_page = requests.get(f"{MN2_BASE_URL}/search?q={query}")
    search_soup = BeautifulSoup(search_page.text, "html.parser")
    items = search_soup.find_all("div", {"class": "book-item"})
    results = []
    for i in items:
        title_element = i.find("div", {"class": "title"}).find("h3").a
        name = title_element.get("title", "No Title").strip()
        url = title_element.get("href", "")
        safe_name = sanitize_filename(name)
        if name and url: results.append({"name": safe_name, "url": url})
    return results
def mn2_get_chapters(item_url: str) -> Tuple[list[dict], str]:
    item_page = requests.get(item_url)
    item_soup = BeautifulSoup(item_page.text, "html.parser")
    title = ""
    title_tag_h1 = item_soup.find("h1", class_=re.compile(r'post-title', re.I))
    if title_tag_h1:
        title = title_tag_h1.text.strip()
    if not title:
        title_tag_head = item_soup.find("title")
        if title_tag_head:
            full_title = title_tag_head.text.strip()
            title = re.sub(r'\s*(-|\|)\s*Toonily.*', '', full_title, flags=re.IGNORECASE).strip()
            title = re.sub(r'^Read\s+', '', title, flags=re.IGNORECASE).strip()
    if not title:
        title = "Untitled"
    safe_title = sanitize_filename(title)
    chapters = []
    chapter_list_tag = item_soup.find("ul", {"id": "chapter-list"})
    if chapter_list_tag:
        for li in chapter_list_tag.find_all("li"):
            a_tag = li.find('a')
            if not a_tag or not a_tag.get('href'): continue
            relative_url = a_tag.get("href")
            chapter_url = urllib.parse.urljoin(item_url, relative_url)
            chapter_name = ""
            strong_tag = a_tag.find("strong")
            if strong_tag: chapter_name = strong_tag.text.strip()
            if not chapter_name:
                clone_a_tag = BeautifulSoup(str(a_tag), 'html.parser').a
                date_tag = clone_a_tag.find("span", class_="update-on")
                if date_tag: date_tag.decompose()
                chapter_name = clone_a_tag.text.strip()
            if not chapter_name.strip(): continue
            safe_chapter_name = sanitize_filename(chapter_name)
            chapters.append({"name": safe_chapter_name, "url": chapter_url})
    chapters.reverse()
    return chapters, safe_title
def mn2_get_chapter_images(chapter_url: str) -> list[str]:
    chapter_page = requests.get(chapter_url)
    chapter_soup = BeautifulSoup(chapter_page.text, "html.parser")
    images_container = chapter_soup.find("div", {"id": "chapter-images"})
    if not images_container: return []
    image_urls = [img.get('data-src') or img.get('src') for img in images_container.find_all("img")]
    return [url.strip() for url in image_urls if url and url.strip()]
def mn2_download_image(url: str, download_path: str) -> bool:
    try:
        res = requests.get(url, headers=MN2_HEADERS, stream=True, timeout=20)
        if res.status_code != 200: return False
        with open(download_path, "wb") as file:
            for chunk in res.iter_content(10*1024): file.write(chunk)
        return True
    except requests.exceptions.RequestException: return False
def mn2_create_zip(files: list[str], output_path: Path, source_dir: Path, del_source=False):
    with zipfile.ZipFile(output_path, "w", zipfile.ZIP_DEFLATED) as file:
        for f in sorted(files):
            file_path = source_dir / f
            if file_path.exists(): file.write(file_path, arcname=f)
    if del_source: shutil.rmtree(source_dir)


MC_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
def mc_get_chapters_and_title(manhwa_url: str) -> Tuple[List[Dict], str]:
    logger.info(f"[{MANHWACLAN_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø²: {manhwa_url}")
    try:
        response = requests.get(manhwa_url, headers=MC_HEADERS, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
    except requests.exceptions.RequestException as e:
        logger.error(f"[{MANHWACLAN_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ {manhwa_url}: {e}")
        return [], ""

    manhwa_title_tag = soup.select_one('.post-title h1')
    manhwa_title = manhwa_title_tag.text.strip() if manhwa_title_tag else "Untitled Manhwa"
    sanitized_title = sanitize_filename(manhwa_title)

    chapters = []
    chapter_list_ul = soup.find('ul', class_='version-chap')
    if chapter_list_ul:
        list_items = chapter_list_ul.find_all('li', class_='wp-manga-chapter')
        for item in list_items:
            link_tag = item.find('a')
            if link_tag and link_tag.has_attr('href'):
                chapter_title = link_tag.text.strip()
                chapter_url = link_tag['href']
                if chapter_title and chapter_url:
                    safe_chapter_title = sanitize_filename(chapter_title)
                    chapters.append({'name': safe_chapter_title, 'url': chapter_url})
    
    if chapters:
        chapters.reverse()
    
    logger.info(f"[{MANHWACLAN_DOMAIN}] {len(chapters)} Ú†Ù¾ØªØ± Ø¨Ø±Ø§ÛŒ '{sanitized_title}' ÛŒØ§ÙØª Ø´Ø¯.")
    return chapters, sanitized_title
def mc_get_chapter_image_urls(chapter_url: str) -> List[str]:
    logger.info(f"[{MANHWACLAN_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµØ§ÙˆÛŒØ± Ø§Ø²: {chapter_url}")
    try:
        response = requests.get(chapter_url, headers=MC_HEADERS, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
    except requests.exceptions.RequestException:
        return []

    images_container = soup.find('div', class_='reading-content')
    if not images_container:
        return []
    
    image_tags = images_container.find_all('img', class_='wp-manga-chapter-img')
    image_urls = [img.get('src', '').strip() for img in image_tags if img.get('src')]
    return image_urls
def mc_download_single_image(args: Tuple[str, str]) -> bool:
    img_url, file_path = args
    try:
        img_response = requests.get(img_url, headers=MC_HEADERS, stream=True, timeout=20)
        img_response.raise_for_status()
        with open(file_path, 'wb') as f:
            for chunk in img_response.iter_content(chunk_size=8192):
                f.write(chunk)
        return True
    except requests.exceptions.RequestException:
        return False


MD_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
def md_get_chapters_and_title(manhwa_url: str) -> Tuple[List[Dict], str]:
    logger.info(f"[{MANGA_DISTRICT_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø²: {manhwa_url}")
    try:
        response = requests.get(manhwa_url, headers=MD_HEADERS, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
    except requests.exceptions.RequestException as e:
        logger.error(f"[{MANGA_DISTRICT_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ {manhwa_url}: {e}")
        return [], ""

    title_element = soup.select_one('div.post-title h1')
    if not title_element:
        logger.error(f"[{MANGA_DISTRICT_DOMAIN}] Ø¹Ù†ÙˆØ§Ù† Ù…Ø§Ù†Ù‡ÙˆØ§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return [], ""
    manhwa_title = title_element.text.strip()
    sanitized_title = sanitize_filename(manhwa_title)

    chapters = []
    chapter_list_element = soup.select_one('ul.version-chap')
    if not chapter_list_element:
        logger.error(f"[{MANGA_DISTRICT_DOMAIN}] Ù„ÛŒØ³Øª Ú†Ù¾ØªØ±Ù‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return [], sanitized_title

    for item in chapter_list_element.find_all('li', class_='wp-manga-chapter'):
        link = item.find('a')
        if link and link.has_attr('href'):
            chapter_title = link.text.strip()
            chapter_url = link['href']
            safe_chapter_title = sanitize_filename(chapter_title)
            chapters.append({'name': safe_chapter_title, 'url': chapter_url})
    
    if chapters:
        chapters.reverse()
    
    logger.info(f"[{MANGA_DISTRICT_DOMAIN}] {len(chapters)} Ú†Ù¾ØªØ± Ø¨Ø±Ø§ÛŒ '{sanitized_title}' ÛŒØ§ÙØª Ø´Ø¯.")
    return chapters, sanitized_title
def md_get_chapter_image_urls(chapter_url: str) -> List[str]:
    logger.info(f"[{MANGA_DISTRICT_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµØ§ÙˆÛŒØ± Ø§Ø²: {chapter_url}")
    try:
        response = requests.get(chapter_url, headers=MD_HEADERS, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
    except requests.exceptions.RequestException as e:
        logger.error(f"[{MANGA_DISTRICT_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ØµÙØ­Ù‡ Ú†Ù¾ØªØ±: {e}")
        return []

    reading_content = soup.find('div', class_='reading-content')
    if not reading_content:
        logger.error(f"[{MANGA_DISTRICT_DOMAIN}] Ù…Ø­ØªÙˆØ§ÛŒ Ú†Ù¾ØªØ± Ø¯Ø± Ø¢Ø¯Ø±Ø³ {chapter_url} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return []

    image_urls = []
    for img in reading_content.find_all('img'):
        img_url = img.get('src', '').strip()
        if not img_url:
            img_url = img.get('data-src', '').strip()
        if img_url:
            image_urls.append(img_url)
    return image_urls
def md_download_single_image(args: Tuple[str, str]) -> bool:
    img_url, file_path = args
    try:
        img_response = requests.get(img_url, headers=MD_HEADERS, stream=True, timeout=20)
        img_response.raise_for_status()
        with open(file_path, 'wb') as f:
            for chunk in img_response.iter_content(chunk_size=8192):
                f.write(chunk)
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"[{MANGA_DISTRICT_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± {img_url}: {e}")
        return False


EROME_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Referer': 'https://www.erome.com/'
}

def er_get_album_media(album_url: str) -> Tuple[str, Dict[str, List[str]]]:
    """
    Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÛŒÚ© Ø¢Ù„Ø¨ÙˆÙ… Ø§Ø² Ø³Ø§ÛŒØª Erome Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ø¹Ù†ÙˆØ§Ù†ØŒ Ù„ÛŒÙ†Ú© Ø¹Ú©Ø³â€ŒÙ‡Ø§ Ùˆ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§).
    """
    logger.info(f"[{EROME_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ù„Ø¨ÙˆÙ…: {album_url}")
    try:
        response = requests.get(album_url, headers=EROME_HEADERS, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        
        title_tag = soup.find('h1')
        album_title = title_tag.text.strip() if title_tag else "Erome Album"
        sanitized_title = sanitize_filename(album_title)

        media_urls = {'images': [], 'videos': []}
        
       
        for video_tag in soup.find_all('video'):
            source_tag = video_tag.find('source')
            if source_tag and source_tag.get('src'):
                media_urls['videos'].append(source_tag['src'])

        
        for img_div in soup.find_all('div', class_='img'):
            if img_div.get('data-src'):
                media_urls['images'].append(img_div['data-src'])

        
        media_urls['images'] = sorted(list(dict.fromkeys(media_urls['images'])))
        media_urls['videos'] = sorted(list(dict.fromkeys(media_urls['videos'])))
        
        logger.info(f"[{EROME_DOMAIN}] Ø¨Ø±Ø§ÛŒ '{sanitized_title}'ØŒ {len(media_urls['images'])} Ø¹Ú©Ø³ Ùˆ {len(media_urls['videos'])} ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ÙØª Ø´Ø¯.")
        return sanitized_title, media_urls

    except requests.exceptions.RequestException as e:
        logger.error(f"[{EROME_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ØµÙØ­Ù‡: {e}")
        return "Error", {}

async def er_get_album_media_selenium(album_url: str, driver) -> Tuple[str, Dict[str, List[str]]]:
    """
    [ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Selenium]
    Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù„Ø¨ÙˆÙ… Ø±Ø§ Ø¨Ø§ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡ Ø¯Ø± ÛŒÚ© Ù…Ø±ÙˆØ±Ú¯Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    ØªØ§ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ù¾Ø±Ø³Ø±Ø¹Øª Ø±Ø§ Ù¾Ø³ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ JavaScript Ø¨Ø¯Ø³Øª Ø¢ÙˆØ±Ø¯.
    """
    logger.info(f"[{EROME_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡ Ø¨Ø§ Selenium Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ: {album_url}")
    driver.get(album_url)
    
    try:
        
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "video, div.img[data-src]"))
        )
        
        
        await asyncio.sleep(2)

        
        soup = BeautifulSoup(driver.page_source, 'html.parser')

        title_tag = soup.find('h1')
        album_title = title_tag.text.strip() if title_tag else "Erome Album"
        sanitized_title = sanitize_filename(album_title)

        media_urls = {'images': [], 'videos': []}
        
        
        for video_tag in soup.find_all('video'):
            source_tag = video_tag.find('source')
            if source_tag and source_tag.get('src'):
                media_urls['videos'].append(source_tag['src'])

        
        for img_div in soup.find_all('div', class_='img'):
            if img_div.get('data-src'):
                media_urls['images'].append(img_div['data-src'])

        media_urls['images'] = sorted(list(dict.fromkeys(media_urls['images'])))
        media_urls['videos'] = sorted(list(dict.fromkeys(media_urls['videos'])))
        
        logger.info(f"[{EROME_DOMAIN}] Ø¨Ø§ SeleniumØŒ {len(media_urls['images'])} Ø¹Ú©Ø³ Ùˆ {len(media_urls['videos'])} ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ÙØª Ø´Ø¯.")
        return sanitized_title, media_urls

    except Exception as e:
        logger.error(f"[{EROME_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ú©Ø§Ø± Ø¨Ø§ Selenium: {e}")
        return "Error", {}


@celery_app.task(name="tasks.process_erome_images", **RETRY_PARAMS)
def process_erome_images_task(chat_id: int, image_urls: list, album_title: str):
    """
    Celery task to download and upload images from an Erome album with retry logic.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(
            chat_id=chat_id,
            text=f"ğŸ“¥ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(image_urls)} Ø¹Ú©Ø³ Ø¨Ø±Ø§ÛŒ Ø¢Ù„Ø¨ÙˆÙ… '{album_title}'..."
        )
        message_id_to_edit = status_message.message_id

        with tempfile.TemporaryDirectory() as temp_dir:
            for i, url in enumerate(image_urls):
                try:
                    await bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=message_id_to_edit,
                        text=f"[{i+1}/{len(image_urls)}] ğŸ–¼ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø¹Ú©Ø³..."
                    )
                    
                    filename = os.path.basename(urllib.parse.urlparse(url).path) or f"erome_img_{i}.jpg"
                    temp_file_path = os.path.join(temp_dir, filename)

                    
                    def _download_image_sync():
                        with requests.get(url, headers=EROME_HEADERS, stream=True, timeout=120) as r:
                            r.raise_for_status()
                            with open(temp_file_path, 'wb') as f:
                                for chunk in r.iter_content(chunk_size=8192):
                                    f.write(chunk)
                    
                    await asyncio.to_thread(_download_image_sync)

                    with open(temp_file_path, 'rb') as photo:
                        await bot.send_photo(chat_id=chat_id, photo=photo, caption=filename)
                    
                    os.remove(temp_file_path)

                except Exception as e:
                    logger.error(f"Failed to process Erome image {url}: {e}")
                    await bot.send_message(chat_id=chat_id, text=f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ú©Ø³: {filename}")
            
            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id_to_edit,
                text=f"âœ… Ø¢Ù¾Ù„ÙˆØ¯ ØªÙ…Ø§Ù… Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ø¢Ù„Ø¨ÙˆÙ… '{album_title}' Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯."
            )

    asyncio.run(_async_worker())


@cooldown_decorator()
async def handle_erome_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    url = update.message.text.strip()
    user_id = update.effective_user.id

    is_allowed, message_text = await check_subscription(user_id, EROME_DOMAIN)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END

    message = await update.message.reply_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {EROME_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±...")
    
    driver = await asyncio.to_thread(setup_driver)
    if not driver:
        await message.edit_text("Ø®Ø·Ø§: Ø¯Ø±Ø§ÛŒÙˆØ± Ù…Ø±ÙˆØ±Ú¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø´Ø¯.")
        return ConversationHandler.END

    try:
        await message.edit_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {EROME_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù„ÛŒÙ†Ú© Ø¨Ø§ Ù…Ø±ÙˆØ±Ú¯Ø±...")
        title, media_urls = await er_get_album_media_selenium(url, driver)

        if not media_urls or (not media_urls.get('images') and not media_urls.get('videos')):
            await message.edit_text("Ù‡ÛŒÚ† Ø¹Ú©Ø³ ÛŒØ§ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø¢Ù„Ø¨ÙˆÙ… ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return ConversationHandler.END
            
        context.user_data['er_media'] = media_urls
        context.user_data['er_title'] = title
        
        num_images = len(media_urls.get('images', []))
        num_videos = len(media_urls.get('videos', []))
        
        keyboard = []
        text = f"âœ… ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯: Ø¢Ù„Ø¨ÙˆÙ… '{title}'\n\n"
        if num_images > 0:
            keyboard.append([InlineKeyboardButton(f"ğŸ–¼ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ {num_images} Ø¹Ú©Ø³", callback_data="er_choice_images")])
            text += f"- {num_images} Ø¹Ú©Ø³\n"
        if num_videos > 0:
            keyboard.append([InlineKeyboardButton(f"ğŸ¬ Ø¯Ø§Ù†Ù„ÙˆØ¯ {num_videos} ÙˆÛŒØ¯ÛŒÙˆ", callback_data="er_choice_videos")])
            text += f"- {num_videos} ÙˆÛŒØ¯ÛŒÙˆ\n"
        if num_images > 0 and num_videos > 0:
            keyboard.append([InlineKeyboardButton("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ø±Ø¯Ùˆ (Ø¹Ú©Ø³ Ùˆ ÙˆÛŒØ¯ÛŒÙˆ)", callback_data="er_choice_both")])

        if not keyboard:
            await message.edit_text("Ù…Ø­ØªÙˆØ§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return ConversationHandler.END

        text += "\nÚ©Ø¯Ø§Ù… Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ØŸ"
        await message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard))
        return EROME_AWAIT_CHOICE

    finally:
        await asyncio.to_thread(driver.quit)


async def er_run_yt_dlp_with_headers(url: str, temp_dir: str, filename: str) -> Tuple[str | None, str]:
    """
    [ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ùˆ Ø§Ø®ØªØµØ§ØµÛŒ]
    ÛŒÚ© ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ yt-dlp Ø±Ø§ Ø¨Ø±Ø§ÛŒ Erome Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ 403 Ø§Ø³Øª.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† run_yt_dlp_process Ø¹Ù…ÙˆÙ…ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """

    
    temp_filename_template = os.path.join(temp_dir, 'initial_download')
    ydl_opts = {
        'format': 'best',
        'outtmpl': temp_filename_template,
        'quiet': False,
        'no_warnings': True,
        'http_headers': EROME_HEADERS 
    }
    
    
    logger.info(f"[{EROME_DOMAIN}] Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ yt-dlp Ùˆ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ...")
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
        
        initial_file = next((os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.startswith('initial_download')), None)
        if not initial_file:
            return None, "ÙØ§ÛŒÙ„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· yt-dlp ÛŒØ§ÙØª Ù†Ø´Ø¯."

    except Exception as e:
        logger.error(f"[{EROME_DOMAIN}] Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ yt-dlp Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}")
        return None, f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§ÙˆÙ„ÛŒÙ‡: {e}"

    
    repaired_file = os.path.join(temp_dir, "repaired.mp4")
    if not repair_video(initial_file, repaired_file):
        return None, "Ø®Ø·Ø§ Ø¯Ø± ØªØ¹Ù…ÛŒØ± ÙˆÛŒØ¯ÛŒÙˆ."
    
    final_path = verify_and_finalize(repaired_file, os.path.join(DOWNLOAD_FOLDER, filename))
    if not final_path:
        return None, "Ø®Ø·Ø§ Ø¯Ø± ØªØ£ÛŒÛŒØ¯ Ù†Ù‡Ø§ÛŒÛŒ ÙØ§ÛŒÙ„."
        
    return final_path, "Ù…ÙˆÙÙ‚ÛŒØª"


async def er_process_single_file(update: Update, context: ContextTypes.DEFAULT_TYPE, user_id: int, media_url: str, is_video: bool, temp_dir_base: str):
    """
    [ØªØ§Ø¨Ø¹ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡]
    ÛŒÚ© ÙØ§ÛŒÙ„ (Ø¹Ú©Ø³ ÛŒØ§ ÙˆÛŒØ¯ÛŒÙˆ) Ø§Ø² Erome Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø®Ø·Ø§ÛŒ Ù…ØªØºÛŒØ± Ø±Ø§ Ø¨Ø±Ø·Ø±Ù Ú©Ø±Ø¯Ù‡
    Ùˆ Ù…Ù†Ø·Ù‚ Ø¬Ø¯ÛŒØ¯ Ø¢Ø±Ø´ÛŒÙˆ Ø¹Ù…ÙˆÙ…ÛŒ/Ø´Ø®ØµÛŒ Ø±Ø§ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    chat_id = update.callback_query.message.chat_id
    filename = media_url.split('/')[-1].split('?')[0] or f"media_{hash(media_url)}"
    
    if is_video:
        
        with tempfile.TemporaryDirectory(dir=temp_dir_base) as temp_dir:
            try:
                
                raw_video_path, status_msg = await er_run_yt_dlp_with_headers(
                    url=media_url,
                    temp_dir=temp_dir,
                    filename=filename
                )
                if not raw_video_path:
                    raise Exception(f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {status_msg}")

                duration, width, height = get_video_metadata(raw_video_path)
                
                
                public_upload_id = await upload_video_with_bot_api(
                    bot=context.bot, 
                    target_chat_id=PUBLIC_ARCHIVE_CHAT_ID, file_path=raw_video_path, thumb_path=None, caption=filename,
                    duration=duration, width=width, height=height
                )
                if not public_upload_id:
                    raise Exception("Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø¹Ù…ÙˆÙ…ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")

                
                custom_thumbnail_id = get_user_thumbnail(user_id)
                watermark_settings = get_user_watermark_settings(user_id)
                user_has_customization = bool(custom_thumbnail_id or watermark_settings.get("enabled"))
                
                if not user_has_customization:
                    
                    add_to_video_cache(media_url, 'erome_default', public_upload_id)
                    await context.bot.copy_message(chat_id=chat_id, from_chat_id=PUBLIC_ARCHIVE_CHAT_ID, message_id=public_upload_id)
                else:
                    
                    path_after_watermark = await asyncio.to_thread(apply_watermark_to_video, raw_video_path, watermark_settings)
                    if not path_after_watermark:
                        raise Exception("Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø§Ø¹Ù…Ø§Ù„ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú©.")
                    
                    custom_thumb_path = None
                    if custom_thumbnail_id:
                        thumb_file = await context.bot.get_file(custom_thumbnail_id)
                        custom_thumb_path = os.path.join(temp_dir, 'custom_thumb.jpg')
                        await thumb_file.download_to_drive(custom_path=custom_thumb_path)
                    
                    personal_archive_id = await get_or_create_personal_archive(user_id)
                    if not personal_archive_id:
                        raise Exception("Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª ÛŒØ§ Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø±Ø´ÛŒÙˆ Ø´Ø®ØµÛŒ.")

                    personal_upload_id = await upload_video_with_bot_api(
                        bot=context.bot, 
                        target_chat_id=personal_archive_id, file_path=path_after_watermark, thumb_path=custom_thumb_path,
                        caption=filename, duration=duration, width=width, height=height
                    )

                    if not personal_upload_id:
                        raise Exception("Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø´Ø®ØµÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
                        
                    await context.bot.copy_message(chat_id=chat_id, from_chat_id=personal_archive_id, message_id=personal_upload_id)
            
            except Exception as e:
                logger.error(f"[{EROME_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆ {media_url}: {e}", exc_info=True)
                await context.bot.send_message(chat_id=chat_id, text=f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆ: {filename}")

    else: 
        with tempfile.TemporaryDirectory(dir=temp_dir_base) as temp_dir:
            temp_file_path = None
            try:
                temp_file_path = os.path.join(temp_dir, filename)
                with requests.get(media_url, headers=EROME_HEADERS, timeout=120, stream=True) as r:
                    r.raise_for_status()
                    with open(temp_file_path, 'wb') as f:
                        shutil.copyfileobj(r.raw, f)
                
                with open(temp_file_path, 'rb') as f:
                    await context.bot.send_photo(chat_id=chat_id, photo=f, caption=filename, read_timeout=120, write_timeout=120)

            except Exception as e:
                logger.error(f"[{EROME_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ú©Ø³ {media_url}: {e}", exc_info=True)
                await context.bot.send_message(chat_id=chat_id, text=f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¹Ú©Ø³: {filename}")


async def process_erome_download(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    [ØªØ§Ø¨Ø¹ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡]
    Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CeleryØŒ Ù‡Ø± ÙØ§ÛŒÙ„ Ø±Ø§ Ø¯Ø± ÛŒÚ© ØªØ³Ú© asyncio Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    ØªØ§ Ø§Ø² Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù† Ø±Ø¨Ø§Øª Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø´ÙˆØ¯.
    """
    query = update.callback_query
    await query.answer()
    choice = query.data
    user_id = query.from_user.id 

    media = context.user_data.get('er_media')
    
    if not media:
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return ConversationHandler.END

    images_to_process = []
    videos_to_process = []

    if choice == 'er_choice_images' or choice == 'er_choice_both':
        images_to_process = media.get('images', [])
    if choice == 'er_choice_videos' or choice == 'er_choice_both':
        videos_to_process = media.get('videos', [])

    if not images_to_process and not videos_to_process:
        await query.edit_message_text("ÙØ§ÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡ Ø¨ÙˆØ¯.")
        return ConversationHandler.END
    
    await query.edit_message_text(f"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ {len(images_to_process) + len(videos_to_process)} ÙØ§ÛŒÙ„ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¢ØºØ§Ø² Ø´Ø¯...")
    
    
    with tempfile.TemporaryDirectory() as temp_dir_base:
        if images_to_process:
            for img_url in images_to_process:
                
                asyncio.create_task(er_process_single_file(
                    update, context, user_id, img_url, is_video=False, temp_dir_base=temp_dir_base
                ))
        
        if videos_to_process:
            for video_url in videos_to_process:
                
                asyncio.create_task(er_process_single_file(
                    update, context, user_id, video_url, is_video=True, temp_dir_base=temp_dir_base
                ))
                
    
    context.user_data.pop('er_media', None)
    context.user_data.pop('er_title', None)
    return ConversationHandler.END



API_BASE_URL = "https://api.comick.fun"
IMAGE_BASE_URL = "https://meo.comick.pictures"



logger = logging.getLogger(__name__)


IMAGE_DOWNLOAD_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/125.0',
    'Referer': f'https://{COMICK_DOMAIN}/'
}

def setup_firefox_driver() -> webdriver.Firefox:
    """
    ÙˆØ¨â€ŒØ¯Ø±Ø§ÛŒÙˆØ± ÙØ§ÛŒØ±ÙØ§Ú©Ø³ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (Headless) Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ùˆ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    logger.info(f"[{COMICK_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø±Ø§ÛŒÙˆØ± ÙØ§ÛŒØ±ÙØ§Ú©Ø³ (GeckoDriver)...")
    try:
        options = FirefoxOptions()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
        
        
        service = FirefoxService(GeckoDriverManager().install())
        driver = webdriver.Firefox(service=service, options=options)
        logger.info(f"[{COMICK_DOMAIN}] âœ“ Ø¯Ø±Ø§ÛŒÙˆØ± ÙØ§ÛŒØ±ÙØ§Ú©Ø³ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ø­Ø§Ù„Øª Headless Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯.")
        return driver
    except Exception as e:
        logger.error(f"[{COMICK_DOMAIN}] âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯Ø±Ø§ÛŒÙˆØ± ÙØ§ÛŒØ±ÙØ§Ú©Ø³: {e}")
        return None

def cm_get_info_and_chapters(comic_url: str, driver: webdriver.Firefox) -> Tuple[str, List[Dict]]:
    """
    Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SeleniumØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÛŒÚ© Ú©Ù…ÛŒÚ© (Ø¹Ù†ÙˆØ§Ù†) Ùˆ Ù„ÛŒØ³Øª Ú†Ù¾ØªØ±Ù‡Ø§ÛŒ Ø¢Ù† Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    logger.info(f"[{COMICK_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡ Ú©Ù…ÛŒÚ© Ø¨Ø§ Ù…Ø±ÙˆØ±Ú¯Ø±: {comic_url}")
    driver.get(comic_url)

    try:
        
        wait = WebDriverWait(driver, 25)
        script_element = wait.until(
            EC.presence_of_element_located((By.ID, '__NEXT_DATA__'))
        )
        
        logger.info(f"[{COMICK_DOMAIN}] Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØµÙØ­Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        script_content = script_element.get_attribute('innerHTML')
        data = json.loads(script_content)
        
        comic_data = data['props']['pageProps']['comic']
        title = comic_data['title']
        hid = comic_data['hid']
        
        logger.info(f"[{COMICK_DOMAIN}] Ú©Ù…ÛŒÚ© Ù¾ÛŒØ¯Ø§ Ø´Ø¯: '{title}' (hid: {hid})")
        logger.info(f"[{COMICK_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ú†Ù¾ØªØ±Ù‡Ø§ Ø§Ø² Ø·Ø±ÛŒÙ‚ API...")

        chapters_api_url = f"{API_BASE_URL}/comic/{hid}/chapters?lang=en&limit=99999"
        
        
        chapter_data = driver.execute_async_script(
            f"var callback = arguments[arguments.length - 1];"
            f"fetch('{chapters_api_url}').then(res => res.json()).then(data => callback(data)).catch(err => callback({{error: err.toString()}}));"
        )

        if 'error' in chapter_data:
            logger.error(f"[{COMICK_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ú†Ù¾ØªØ±Ù‡Ø§: {chapter_data['error']}")
            return None, []

        chapters = chapter_data.get('chapters', [])

        if not chapters:
            logger.warning(f"[{COMICK_DOMAIN}] Ù‡ÛŒÚ† Ú†ÛŒØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ '{title}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return title, []

        
        chapters.sort(key=lambda x: float(x.get('chap', 0)) if str(x.get('chap', 0)).replace('.', '', 1).isdigit() else 0)
        
        
        adapted_chapters = [
            {'name': f"Chapter {c.get('chap', 'N/A')}" + (f" - {c.get('title')}" if c.get('title') else ""), 'hid': c.get('hid')}
            for c in chapters
        ]

        logger.info(f"[{COMICK_DOMAIN}] âœ“ ØªØ¹Ø¯Ø§Ø¯ {len(adapted_chapters)} Ú†Ù¾ØªØ± Ø¨Ø±Ø§ÛŒ '{title}' Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
        return title, adapted_chapters

    except Exception as e:
        logger.error(f"[{COMICK_DOMAIN}] âŒ Ø®Ø·Ø§ÛŒÛŒ Ù‡Ù†Ú¯Ø§Ù… Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Selenium Ø±Ø® Ø¯Ø§Ø¯: {e}", exc_info=True)
        return None, []


def cm_get_chapter_image_urls(chapter_hid: str, driver: webdriver.Firefox) -> List[str]:
    """
    Ù„ÛŒØ³Øª URL ØªØµØ§ÙˆÛŒØ± ÛŒÚ© Ú†Ù¾ØªØ± Ù…Ø´Ø®Øµ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HID Ø¢Ù† Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø§Ø² Selenium Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ± Ø²Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ (Ù…Ø§Ù†Ù†Ø¯ 403 Forbidden) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    logger.info(f"[{COMICK_DOMAIN}] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª URL ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ú†Ù¾ØªØ± Ø¨Ø§ hid: {chapter_hid} Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø±ÙˆØ±Ú¯Ø±...")
    api_url = f"{API_BASE_URL}/chapter/{chapter_hid}"
    try:
        
        chapter_data = driver.execute_async_script(
            "var callback = arguments[arguments.length - 1];"
            f"fetch('{api_url}').then(res => res.json()).then(data => callback(data)).catch(err => callback({{error: err.toString()}}));"
        )

        if 'error' in chapter_data:
            logger.error(f"[{COMICK_DOMAIN}] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú†Ù¾ØªØ± {chapter_hid} Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù…Ø±ÙˆØ±Ú¯Ø±: {chapter_data['error']}")
            return []

        images = chapter_data.get('chapter', {}).get('md_images', [])
        if not images:
            logger.warning(f"[{COMICK_DOMAIN}] Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ú†Ù¾ØªØ± Ø¨Ø§ hid: {chapter_hid} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return []
            
        image_urls = [f"{IMAGE_BASE_URL}/{img['b2key']}" for img in images]
        logger.info(f"[{COMICK_DOMAIN}] ØªØ¹Ø¯Ø§Ø¯ {len(image_urls)} ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ú†Ù¾ØªØ± Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
        return image_urls

    except Exception as e:
        logger.error(f"[{COMICK_DOMAIN}] Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ú†Ù¾ØªØ± {chapter_hid}: {e}")
        return []

def cm_download_single_image(args: Tuple[str, str]) -> bool:
    """
    ÛŒÚ© ØªØµÙˆÛŒØ± Ø±Ø§ Ø§Ø² URL Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø¯Ø± Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    img_url, file_path = args
    try:
        img_response = requests.get(img_url, headers=IMAGE_DOWNLOAD_HEADERS, stream=True, timeout=25)
        img_response.raise_for_status()
        
        with open(file_path, 'wb') as f:
            for chunk in img_response.iter_content(chunk_size=8192):
                f.write(chunk)
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"[{COMICK_DOMAIN}] Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± {img_url} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}")
        return False


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """[Ù†Ø³Ø®Ù‡ ÙˆÛŒØ±Ø§ÛŒØ´ Ø´Ø¯Ù‡] Ø¯Ø³ØªÙˆØ± /start Ø¨Ø§ Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø¯Ø§Ø¦Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±."""
    user = update.effective_user
    user_data = get_user_data(user.id) 
    
    if user_data.get('username') != user.username:
        user_data['username'] = user.username
        update_user_data(user.id, user_data)
    
    start_message = (
        "Ø³Ù„Ø§Ù…! Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù…ÙˆÙ„ØªÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø± Ø®ÙˆØ´ Ø§ÙˆÙ…Ø¯ÛŒØ¯\n"
        "ÛŒÚ© Ù„ÛŒÙ†Ú© Ø§Ø² Ø³Ø§ÛŒØª Ù‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡ Ø¨ÙØ±Ø³ØªÛŒØ¯ ØªØ§ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ù†Ù…"
    )
    
    
    user_keyboard = [["Ø±Ø§Ù‡Ù†Ù…Ø§"]]
    reply_markup = ReplyKeyboardMarkup(user_keyboard, resize_keyboard=True)
    
    await update.message.reply_text(start_message, reply_markup=reply_markup)


@cooldown_decorator()
async def handle_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    
    if not update.message or not update.message.text:
        return
    url = update.message.text.strip()
    
    if not url.startswith("http"):
        return

    user_id = update.effective_user.id
    domain = urllib.parse.urlparse(url).netloc.lower().replace('www.', '')

    is_allowed, message = await check_subscription(user_id, domain)
    if not is_allowed:
        await update.message.reply_text(message)
        return 
        
    logger.info(f"Ù„ÛŒÙ†Ú© ØªÙˆØ³Ø· Ú©Ù†ØªØ±Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ØŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ yt-dlp: {url}")
    await handle_yt_dlp_link(update, context, url)


@cooldown_decorator()
async def handle_pornhub_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    Handles links from video sites like Pornhub and Eporner.
    This corrected version dynamically detects the domain from the URL.
    """
    if not update.message or not update.message.text:
        return
    url = update.message.text.strip()
    user_id = update.effective_user.id

    parsed_url = urllib.parse.urlparse(url)
    domain = parsed_url.netloc.lower().replace('www.', '')

    
    if domain not in [PORNHUB_DOMAIN, EPORNER_DOMAIN, XVIDEOS_DOMAIN]:
        
        logger.warning(f"Handler received an unexpected domain: {domain}")
        
        return
    
        
    is_allowed, message = await check_subscription(user_id, domain)
    if not is_allowed:
        await update.message.reply_text(message)
        return

    logger.info(f"Link from {domain} received, passing to yt-dlp handler: {url}")
    await handle_yt_dlp_link(update, context, url)




def run_yt_dlp_process(url, temp_dir, format_id, final_filename):
    initial_file = download_video(url, temp_dir, format_id)
    if not initial_file: return None, "Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯."
    repaired_file = os.path.join(temp_dir, "repaired.mp4")
    if not repair_video(initial_file, repaired_file): return None, "Ø®Ø·Ø§ Ø¯Ø± ØªØ¹Ù…ÛŒØ±."
    final_path = verify_and_finalize(repaired_file, final_filename)
    if not final_path: return None, "Ø®Ø·Ø§ Ø¯Ø± ØªØ£ÛŒÛŒØ¯."
    return final_path, "Ù…ÙˆÙÙ‚ÛŒØª"


def generate_thumbnail_from_video(video_path: str, output_path: str) -> bool:
    """
    ÛŒÚ© ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ø§Ø² ÙØ§ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ffmpeg Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡ Ø§ÙˆÙ„ ÙˆÛŒØ¯ÛŒÙˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    try:
        (
            ffmpeg
            .input(video_path, ss=1)
            .output(output_path, vframes=1)
            .overwrite_output()
            .run(capture_stdout=True, capture_stderr=True)
        )
        logger.info(f"ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ù…Ø³ÛŒØ± {output_path} Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
        return True
    except ffmpeg.Error as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª ØªØ§Ù…Ø¨Ù†ÛŒÙ„: {e.stderr.decode()}")
        return False


@celery_app.task(name="tasks.download_and_upload_video")
def download_and_upload_video_task(chat_id: int, url: str, selected_format: str, video_info_json: str, user_id: int):
    """
    [Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„]
    Ø§ÛŒÙ† ØªØ³Ú© Ø§Ú©Ù†ÙˆÙ† ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø±Ø§ÛŒ Ù†Ø³Ø®Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    
    video_info = json.loads(video_info_json) if video_info_json else {}

    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(chat_id=chat_id, text="ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² ØµÙ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯...")
        message_id_to_edit = status_message.message_id

        custom_thumbnail_id = get_user_thumbnail(user_id)
        watermark_settings = get_user_watermark_settings(user_id)
        user_has_customization = bool(custom_thumbnail_id or watermark_settings.get("enabled"))
        
        title = sanitize_filename(video_info.get('title', 'untitled_video'))
        final_filename = os.path.join(DOWNLOAD_FOLDER, f"{title}.mp4")

        with tempfile.TemporaryDirectory() as temp_dir:
            try:
                
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {title}...")
                raw_video_path, status_msg = await asyncio.to_thread(
                    run_yt_dlp_process, url, temp_dir, selected_format, final_filename
                )
                if not raw_video_path:
                    raise Exception(f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {status_msg}")

                duration, width, height = await asyncio.to_thread(get_video_metadata, raw_video_path)

                
                default_thumb_path = None
                thumbnail_url = video_info.get('thumbnail')
                
                if thumbnail_url:
                    try:
                        thumb_filename = os.path.basename(urllib.parse.urlparse(thumbnail_url).path) or "default_thumb.jpg"
                        temp_thumb_path = os.path.join(temp_dir, thumb_filename)
                        
                        def _download_thumb():
                            with requests.get(thumbnail_url, stream=True, timeout=20) as r:
                                r.raise_for_status()
                                with open(temp_thumb_path, 'wb') as f:
                                    shutil.copyfileobj(r.raw, f)
                            return temp_thumb_path
                        
                        default_thumb_path = await asyncio.to_thread(_download_thumb)
                        logger.info(f"ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: {default_thumb_path}")

                    except Exception as e:
                        logger.warning(f"Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø² {thumbnail_url} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}")
                        default_thumb_path = None
                
                
                if not default_thumb_path or not os.path.exists(default_thumb_path):
                    logger.info("Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ø§Ø² ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†...")
                    fallback_thumb_path = os.path.join(temp_dir, 'fallback_thumb.jpg')
                    thumb_generated = await asyncio.to_thread(
                        generate_thumbnail_from_video, raw_video_path, fallback_thumb_path
                    )
                    if thumb_generated:
                        default_thumb_path = fallback_thumb_path
                

                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø³Ø®Ù‡ Ø®Ø§Ù… Ø¨Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø¹Ù…ÙˆÙ…ÛŒ...")
                
                public_upload_id = await upload_video_with_bot_api(
                    bot=bot, 
                    target_chat_id=PUBLIC_ARCHIVE_CHAT_ID, 
                    file_path=raw_video_path, 
                    thumb_path=default_thumb_path,
                    caption=title,
                    duration=duration, width=width, height=height
                )
                if not public_upload_id:
                    raise Exception("Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø¹Ù…ÙˆÙ…ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")

                
                if not user_has_customization:
                    add_to_video_cache(url, selected_format, public_upload_id)
                    await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ“¨ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§...")
                    await bot.copy_message(chat_id=chat_id, from_chat_id=PUBLIC_ARCHIVE_CHAT_ID, message_id=public_upload_id)
                    await bot.delete_message(chat_id=chat_id, message_id=message_id_to_edit)
                    return

                
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ¨ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¹Ù…Ø§Ù„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø´Ø®ØµÛŒ...")
                
                path_after_watermark = await asyncio.to_thread(apply_watermark_to_video, raw_video_path, watermark_settings)
                if not path_after_watermark:
                    raise Exception("Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø§Ø¹Ù…Ø§Ù„ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú©.")

                custom_thumb_path = None
                if custom_thumbnail_id:
                    thumb_file = await bot.get_file(custom_thumbnail_id)
                    custom_thumb_path = os.path.join(temp_dir, 'custom_thumb.jpg')
                    await thumb_file.download_to_drive(custom_path=custom_thumb_path)
                
                personal_archive_id = await get_or_create_personal_archive(user_id)
                if not personal_archive_id:
                    raise Exception("Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª ÛŒØ§ Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø±Ø´ÛŒÙˆ Ø´Ø®ØµÛŒ.")

                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø³Ø®Ù‡ Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø´Ù…Ø§...")
                personal_upload_id = await upload_video_with_bot_api(
                    bot=bot, 
                    target_chat_id=personal_archive_id, file_path=path_after_watermark, thumb_path=custom_thumb_path,
                    caption=title, duration=duration, width=width, height=height
                )
                
                if personal_upload_id:
                    await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text="ğŸ“¨ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§...")
                    await bot.copy_message(chat_id=chat_id, from_chat_id=personal_archive_id, message_id=personal_upload_id)
                    await bot.delete_message(chat_id=chat_id, message_id=message_id_to_edit)
                else:
                    raise Exception("Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ø¢Ø±Ø´ÛŒÙˆ Ø´Ø®ØµÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
            
            except Exception as e:
                logger.error(f"Celery Video Task Error: {e}", exc_info=True)
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø® Ø¯Ø§Ø¯: {e}")
            finally:
                if os.path.exists(final_filename):
                    os.remove(final_filename)

    asyncio.run(_async_worker())


@celery_app.task(name="tasks.process_gallery_dl")
def process_gallery_dl_task(chat_id: int, download_path: str, url: str, create_zip: bool):
    """
    Celery task to download from gallery-dl supported sites and upload to Telegram.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = None
        
        
        async def _run_gallery_dl_command():
            logger.info(f"[gallery-dl] Starting download from: {url}")
            command = ['gallery-dl', '-D', download_path, url]
            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()
            if process.returncode != 0:
                error_message = stderr.decode('utf-8', errors='ignore').strip()
                logger.error(f"[gallery-dl] Error during download. Code: {process.returncode}\n{error_message}")
                return None, error_message
            
            all_files = [os.path.join(root, file) for root, _, files in os.walk(download_path) for file in sorted(files)]
            return all_files, None

        try:
            status_message = await bot.send_message(
                chat_id=chat_id,
                text=f"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² '{urllib.parse.urlparse(url).netloc}' Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯..."
            )
            message_id_to_edit = status_message.message_id

            downloaded_files, error = await _run_gallery_dl_command()

            if error or not downloaded_files:
                error_text = error or 'Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.'
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {error_text}")
                return

            if create_zip:
                await bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=message_id_to_edit,
                    text="ğŸ—œï¸ Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡..."
                )
                domain = urllib.parse.urlparse(url).netloc.replace('www.', '').split('.')[0]
                path_slug = urllib.parse.urlparse(url).path.strip('/').replace('/', '_')
                zip_base_name = sanitize_filename(f"{domain}_{path_slug if path_slug else 'gallery'}")
                zip_output_path = os.path.join(DOWNLOAD_FOLDER, f"{zip_base_name}.zip")
                
                await asyncio.to_thread(create_zip_from_folder, download_path, zip_output_path)
                
                await bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=message_id_to_edit,
                    text=f"ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯: {os.path.basename(zip_output_path)}..."
                )
                with open(zip_output_path, 'rb') as doc:
                    await bot.send_document(chat_id=chat_id, document=doc, caption=os.path.basename(zip_output_path))
                os.remove(zip_output_path)
            else:
                total_files = len(downloaded_files)
                for i, file_path in enumerate(downloaded_files):
                    filename = os.path.basename(file_path)
                    await bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=message_id_to_edit,
                        text=f"ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ {i+1} Ø§Ø² {total_files}: {filename}..."
                    )
                    
                    file_ext = os.path.splitext(filename)[1].lower()
                    IMAGE_EXTS = ['.jpg', '.jpeg', '.png', '.webp']
                    VIDEO_EXTS = ['.mp4', '.mkv', '.webm']
                    
                    try:
                        with open(file_path, 'rb') as f:
                            if file_ext in IMAGE_EXTS:
                                await bot.send_photo(chat_id=chat_id, photo=f, caption=filename)
                            elif file_ext in VIDEO_EXTS:
                                await bot.send_video(chat_id=chat_id, video=f, caption=filename, supports_streaming=True)
                            else:
                                await bot.send_document(chat_id=chat_id, document=f, caption=filename)
                    except Exception as upload_error:
                        logger.error(f"Error sending file {filename}: {upload_error}")
                        await bot.send_message(chat_id=chat_id, text=f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„: {filename}")

            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id_to_edit,
                text="âœ… ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù†Ø¯."
            )
        except Exception as e:
            logger.error(f"Celery Gallery-DL Task Error: {e}", exc_info=True)
            if status_message:
                await bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=status_message.message_id,
                    text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø® Ø¯Ø§Ø¯: {e}"
                )
        finally:
            if os.path.exists(download_path):
                shutil.rmtree(download_path)

    asyncio.run(_async_worker())


@cooldown_decorator()
async def handle_gallery_dl_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    url = update.message.text.strip()
    user_id = update.effective_user.id
    domain = urllib.parse.urlparse(url).netloc.lower().replace('www.', '')
    is_allowed, message_text = await check_subscription(user_id, domain)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END

    
    should_ask_for_zip = any(zip_site in domain for zip_site in GALLERY_DL_ZIP_SITES)
    
    if should_ask_for_zip:
        message = await update.message.reply_text("Ø§ÛŒÙ† Ø³Ø§ÛŒØª Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ§ÛŒÙ„ ÙØ´Ø±Ø¯Ù‡ (ZIP) Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ÙØ´Ø±Ø¯Ù‡ Ø´ÙˆÙ†Ø¯ØŸ")
        await message.edit_reply_markup(
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("Ø¨Ù„Ù‡ØŒ ÙØ§ÛŒÙ„ ZIP Ø¨Ø³Ø§Ø²", callback_data="gdl_zip_yes")],
                [InlineKeyboardButton("Ù†Ù‡ØŒ Ø¨Ù‡ ØµÙˆØ±Øª ÙØ§ÛŒÙ„ Ù…Ø¬Ø²Ø§ Ø¨ÙØ±Ø³Øª", callback_data="gdl_zip_no")]
            ])
        )
        
        context.user_data['gdl_url'] = url
        return GALLERY_DL_AWAIT_ZIP_OPTION
    else:
        
        await update.message.reply_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² '{domain}' Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")
        task_id = f"gdl_{update.effective_chat.id}_{update.message.message_id}"
        download_path = os.path.join(DOWNLOAD_FOLDER, task_id)
        
        process_gallery_dl_task.delay(
            chat_id=update.effective_chat.id,
            download_path=download_path,
            url=url,
            create_zip=False 
        )
        return ConversationHandler.END

async def process_gallery_dl_upload(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    
    create_zip = (query.data == 'gdl_zip_yes')
    url = context.user_data.get('gdl_url')

    if not url:
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        return ConversationHandler.END

    await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² '{urllib.parse.urlparse(url).netloc}' Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    task_id = f"gdl_{query.message.chat.id}_{query.message.message_id}"
    download_path = os.path.join(DOWNLOAD_FOLDER, task_id)
    
    process_gallery_dl_task.delay(
        chat_id=query.message.chat.id,
        download_path=download_path,
        url=url,
        create_zip=create_zip
    )
    
    context.user_data.pop('gdl_url', None)
    return ConversationHandler.END



def create_chapter_keyboard(chapters: list, selected_indices: list, page: int, prefix: str) -> InlineKeyboardMarkup:
    keyboard_rows = []
    items_per_page = 20
    start_index = page * items_per_page
    end_index = start_index + items_per_page
    paginated_chapters = chapters[start_index:end_index]
    row = []
    for i, chapter in enumerate(paginated_chapters):
        global_index = start_index + i
        text = f"âœ… {chapter['name']}" if global_index in selected_indices else chapter['name']
        row.append(InlineKeyboardButton(text, callback_data=f"{prefix}_toggle_{global_index}"))
        if len(row) == 2: keyboard_rows.append(row); row = []
    if row: keyboard_rows.append(row)
    nav_row = []
    if page > 0: nav_row.append(InlineKeyboardButton("â—€ï¸ Ù‚Ø¨Ù„ÛŒ", callback_data=f"{prefix}_page_{page-1}"))
    if end_index < len(chapters): nav_row.append(InlineKeyboardButton("Ø¨Ø¹Ø¯ÛŒ â–¶ï¸", callback_data=f"{prefix}_page_{page+1}"))
    if nav_row: keyboard_rows.append(nav_row)
    keyboard_rows.append([InlineKeyboardButton("Ø§Ù†ØªØ®Ø§Ø¨ Ù‡Ù…Ù‡", callback_data=f"{prefix}_select_all"), InlineKeyboardButton("Ø­Ø°Ù Ù‡Ù…Ù‡", callback_data=f"{prefix}_deselect_all")])
    keyboard_rows.append([InlineKeyboardButton("âœ… Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯", callback_data=f"{prefix}_start_download")])
    return InlineKeyboardMarkup(keyboard_rows)


@celery_app.task(name="tasks.process_cosplaytele_images")
def process_cosplaytele_images_task(chat_id: int, image_urls: list, page_slug: str):
    """
    Celery task to download and upload images from a CosplayTele gallery.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(
            chat_id=chat_id,
            text=f"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(image_urls)} Ø¹Ú©Ø³ Ø§Ø² ØµÙ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯..."
        )
        message_id_to_edit = status_message.message_id
        
        specific_folder = Path(DOWNLOAD_FOLDER) / page_slug
        specific_folder.mkdir(parents=True, exist_ok=True)
        
        try:
            def _download_all_images_sync():
                tasks = []
                for i, url in enumerate(image_urls):
                    filename = os.path.basename(urllib.parse.urlparse(url).path) or f"image_{i+1}.jpg"
                    file_path = specific_folder / filename
                    tasks.append((url, str(file_path)))
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                    executor.map(ct_download_single_image, tasks)
                return tasks 

            
            downloaded_tasks = await asyncio.to_thread(_download_all_images_sync)

            total_images = len(downloaded_tasks)
            for i, (url, file_path_str) in enumerate(downloaded_tasks):
                await bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=message_id_to_edit,
                    text=f"[{i+1}/{total_images}] ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ø¹Ú©Ø³: {os.path.basename(file_path_str)}..."
                )
                file_path = Path(file_path_str)
                if file_path.exists():
                    try:
                        with open(file_path, 'rb') as photo:
                            await bot.send_photo(chat_id=chat_id, photo=photo, caption=file_path.name)
                    except Exception as e:
                        logger.error(f"[{COSPLAYTELE_DOMAIN}] Error uploading photo {file_path.name}: {e}")
                        await bot.send_message(chat_id=chat_id, text=f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯ Ø¹Ú©Ø³: {file_path.name}")
                    finally:
                        os.remove(file_path)

            if os.path.isdir(specific_folder) and not os.listdir(specific_folder):
                os.rmdir(specific_folder)
            
            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id_to_edit,
                text="âœ… Ø¢Ù¾Ù„ÙˆØ¯ ØªÙ…Ø§Ù… Ø¹Ú©Ø³â€ŒÙ‡Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯."
            )
        except Exception as e:
            logger.error(f"Celery CosplayTele Task Error: {e}", exc_info=True)
            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id_to_edit,
                text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¹Ú©Ø³â€ŒÙ‡Ø§ Ø±Ø® Ø¯Ø§Ø¯: {e}"
            )

    asyncio.run(_async_worker())


@cooldown_decorator()
async def handle_cosplaytele_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    url = update.message.text.strip()
    user_id = update.effective_user.id
    is_allowed, message_text = await check_subscription(user_id, COSPLAYTELE_DOMAIN)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END

    message = await update.message.reply_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {COSPLAYTELE_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù„ÛŒÙ†Ú©...")
    
    media_urls = await asyncio.to_thread(ct_analyze_and_extract_media, url)
    
    if not media_urls or (not media_urls.get('images') and not media_urls.get('videos')):
        await message.edit_text("Ù‡ÛŒÚ† Ø¹Ú©Ø³ ÛŒØ§ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø± Ø§ÛŒÙ† ØµÙØ­Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return ConversationHandler.END
        
    context.user_data['ct_media_urls'] = media_urls
    
    num_images = len(media_urls.get('images', []))
    num_videos = len(media_urls.get('videos', []))
    
    keyboard = []
    if num_images > 0:
        keyboard.append([InlineKeyboardButton(f"ğŸ–¼ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ {num_images} Ø¹Ú©Ø³", callback_data="ct_choice_images")])
    if num_videos > 0:
        keyboard.append([InlineKeyboardButton(f"ğŸ¬ Ø¯Ø§Ù†Ù„ÙˆØ¯ {num_videos} ÙˆÛŒØ¯ÛŒÙˆ", callback_data="ct_choice_videos")])
    
    if not keyboard:
        await message.edit_text("Ù…Ø­ØªÙˆØ§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return ConversationHandler.END

    page_slug = urllib.parse.urlparse(url).path.strip('/').replace('/', '-') or "gallery"
    context.user_data['ct_page_slug'] = page_slug

    await message.edit_text(
        f"âœ… ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯:\n- {num_images} Ø¹Ú©Ø³\n- {num_videos} ÙˆÛŒØ¯ÛŒÙˆ\n\nÚ©Ø¯Ø§Ù… Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ØŸ",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )
    return CT_AWAIT_USER_CHOICE

async def process_cosplaytele_download(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    choice = query.data
    
    media_urls = context.user_data.get('ct_media_urls')
    page_slug = context.user_data.get('ct_page_slug', 'cosplaytele-gallery')

    if not media_urls:
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        return ConversationHandler.END

    if choice == 'ct_choice_images':
        image_urls = media_urls.get('images', [])
        if not image_urls:
            await query.edit_message_text("Ù‡ÛŒÚ† Ø¹Ú©Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø± Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        else:
            
            process_cosplaytele_images_task.delay(
                chat_id=query.message.chat_id,
                image_urls=image_urls,
                page_slug=page_slug
            )
            await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(image_urls)} Ø¹Ú©Ø³ Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    elif choice == 'ct_choice_videos':
        video_urls = media_urls.get('videos', [])
        if not video_urls:
            await query.edit_message_text("Ù‡ÛŒÚ† ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø± Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        else:
            
            for video_url in video_urls:
                
                download_and_upload_video_task.delay(
                    chat_id=query.message.chat_id,
                    url=video_url,
                    selected_format='best', 
                    user_id=query.from_user.id,
                    video_info_json=None 
                )
            await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(video_urls)} ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    context.user_data.pop('ct_media_urls', None)
    context.user_data.pop('ct_page_slug', None)
    return ConversationHandler.END


@celery_app.task(name="tasks.process_mangadistrict")
def process_mangadistrict_task(chat_id: int, manhwa_title: str, chapters_to_download: list, create_zip: bool):
    """
    Celery task to download chapters from MangaDistrict.
    This runs in the background on a Celery worker.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(
            chat_id=chat_id, 
            text=f"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ '{manhwa_title}' Ø§Ø² ØµÙ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯..."
        )
        message_id_to_edit = status_message.message_id

        manhwa_folder = Path(DOWNLOAD_FOLDER) / sanitize_filename(manhwa_title)
        manhwa_folder.mkdir(parents=True, exist_ok=True)

        try:
            total_chapters = len(chapters_to_download)
            for i, chapter in enumerate(chapters_to_download):
                await bot.edit_message_text(
                    chat_id=chat_id, 
                    message_id=message_id_to_edit, 
                    text=f"[{i+1}/{total_chapters}] ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {chapter['name']}..."
                )
                
                temp_images_path = manhwa_folder / (sanitize_filename(chapter['name']) + "_temp_md")
                temp_images_path.mkdir(exist_ok=True)

                
                image_urls = await asyncio.to_thread(md_get_chapter_image_urls, chapter['url'])

                if not image_urls:
                    await bot.send_message(chat_id=chat_id, text=f"âŒ ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    shutil.rmtree(temp_images_path)
                    continue

                def _download_images_sync():
                    tasks = [(url, str(temp_images_path / f"{j+1:03d}{os.path.splitext(url.split('?')[0])[-1] or '.jpg'}")) for j, url in enumerate(image_urls)]
                    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                        executor.map(md_download_single_image, tasks)
                
                await asyncio.to_thread(_download_images_sync)

                downloaded_files = sorted(os.listdir(temp_images_path))
                if not downloaded_files:
                    await bot.send_message(chat_id=chat_id, text=f"âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
                    shutil.rmtree(temp_images_path)
                    continue

                if create_zip:
                    await bot.edit_message_text(
                        chat_id=chat_id, 
                        message_id=message_id_to_edit, 
                        text=f"[{i+1}/{total_chapters}] ğŸ—œï¸ Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ: {chapter['name']}..."
                    )
                    
                    zip_path = manhwa_folder / f"{manhwa_title} - {sanitize_filename(chapter['name'])}.zip"
                    await asyncio.to_thread(create_zip_from_folder, str(temp_images_path), str(zip_path))
                    
                    with open(zip_path, 'rb') as doc:
                        await bot.send_document(chat_id=chat_id, document=doc, caption=zip_path.name)
                    os.remove(zip_path)
                else:
                    await bot.edit_message_text(
                        chat_id=chat_id, 
                        message_id=message_id_to_edit, 
                        text=f"[{i+1}/{total_chapters}] ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ {len(downloaded_files)} Ø¹Ú©Ø³..."
                    )
                    for img_file in downloaded_files:
                        with open(temp_images_path / img_file, 'rb') as photo:
                            await bot.send_photo(chat_id=chat_id, photo=photo, caption=img_file)
                
                shutil.rmtree(temp_images_path)

            await bot.edit_message_text(
                chat_id=chat_id, 
                message_id=message_id_to_edit, 
                text=f"âœ… ØªÙ…Ø§Ù… Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ '{manhwa_title}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯."
            )
        except Exception as e:
            logger.error(f"Celery MangaDistrict Task Error: {e}", exc_info=True)
            await bot.edit_message_text(
                chat_id=chat_id, 
                message_id=message_id_to_edit, 
                text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø® Ø¯Ø§Ø¯: {e}"
            )

    asyncio.run(_async_worker())

@cooldown_decorator()
async def handle_mangadistrict_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    url = update.message.text.strip()
    user_id = update.effective_user.id
    is_allowed, message_text = await check_subscription(user_id, MANGA_DISTRICT_DOMAIN)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END

    message = await update.message.reply_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {MANGA_DISTRICT_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú©...")
    
    
    chapters, title = await asyncio.to_thread(md_get_chapters_and_title, url)
    
    if not chapters:
        await message.edit_text("Ù‡ÛŒÚ† Ú†Ù¾ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯.")
        return ConversationHandler.END
    
    context.user_data['md_chapters'] = chapters
    context.user_data['md_title'] = title
    context.user_data['md_selected_indices'] = []
    context.user_data['md_current_page'] = 0
    
    keyboard = create_chapter_keyboard(chapters, [], 0, "md")
    await message.edit_text(
        f"âœ… {len(chapters)} Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ '{title}' ÛŒØ§ÙØª Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        reply_markup=keyboard
    )
    return MD_SELECTING_CHAPTERS

async def chapter_selection_md_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    data = query.data
    chapters = context.user_data.get('md_chapters', [])
    selected_indices = context.user_data.get('md_selected_indices', [])
    page = context.user_data.get('md_current_page', 0)

    if data.startswith("md_toggle_"):
        index = int(data.split('_')[-1])
        if index in selected_indices:
            selected_indices.remove(index)
        else:
            selected_indices.append(index)
    elif data.startswith("md_page_"):
        page = int(data.split('_')[-1])
    elif data == "md_select_all":
        selected_indices = list(range(len(chapters)))
    elif data == "md_deselect_all":
        selected_indices = []
    elif data == "md_start_download":
        if not selected_indices:
            await query.answer("Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù‚Ø³Ù…Øª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.", show_alert=True)
            return MD_SELECTING_CHAPTERS
        keyboard = [
            [InlineKeyboardButton("Ø¨Ù„Ù‡ØŒ ÙØ§ÛŒÙ„ ZIP Ø¨Ø³Ø§Ø²", callback_data="md_zip_yes")],
            [InlineKeyboardButton("Ù†Ù‡ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª", callback_data="md_zip_no")]
        ]
        await query.edit_message_text(
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÙØ´Ø±Ø¯Ù‡ (ZIP) Ø´ÙˆÙ†Ø¯ØŸ",
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
        return MD_AWAIT_ZIP_OPTION
        
    context.user_data['md_selected_indices'] = selected_indices
    context.user_data['md_current_page'] = page
    keyboard = create_chapter_keyboard(chapters, selected_indices, page, "md")
    await query.edit_message_reply_markup(reply_markup=keyboard)
    return MD_SELECTING_CHAPTERS


async def process_mangadistrict_download(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    
    create_zip = (query.data == 'md_zip_yes')
    chapters_data = context.user_data.get('md_chapters', [])
    manhwa_title = context.user_data.get('md_title', 'Unknown')
    selected_indices = context.user_data.get('md_selected_indices', [])
    
    if not all([chapters_data, manhwa_title, selected_indices is not None]):
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return ConversationHandler.END

    chapters_to_download = [chapters_data[i] for i in sorted(selected_indices)]

    
    process_mangadistrict_task.delay(
        chat_id=query.message.chat.id,
        manhwa_title=manhwa_title,
        chapters_to_download=chapters_to_download,
        create_zip=create_zip
    )

    await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(chapters_to_download)} Ù‚Ø³Ù…Øª Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    
    for key in list(context.user_data.keys()):
        if key.startswith('md_'):
            context.user_data.pop(key)
            
    return ConversationHandler.END


@celery_app.task(name="tasks.process_comick")
def process_comick_task(chat_id: int, manhwa_title: str, chapters_to_download: list, create_zip: bool):
    """
    Celery task to download chapters from Comick.io using Selenium.
    This runs in the background on a Celery worker.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(
            chat_id=chat_id,
            text=f"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ '{manhwa_title}' Ø§Ø² ØµÙ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±..."
        )
        message_id_to_edit = status_message.message_id

        manhwa_folder = Path(DOWNLOAD_FOLDER) / sanitize_filename(manhwa_title)
        manhwa_folder.mkdir(parents=True, exist_ok=True)

        
        def _download_all_chapters_sync(loop):
            driver = None
            try:
                driver = setup_firefox_driver()
                if not driver:
                    raise Exception("Failed to initialize Firefox driver.")

                
                logger.info(f"[{COMICK_DOMAIN}] Warming up browser session...")
                driver.get(f"https://{COMICK_DOMAIN}/")
                

                total_chapters = len(chapters_to_download)
                for i, chapter in enumerate(chapters_to_download):
                    
                    async def update_status():
                        await bot.edit_message_text(
                            chat_id=chat_id,
                            message_id=message_id_to_edit,
                            text=f"[{i+1}/{total_chapters}] ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {chapter['name']}..."
                        )
                    asyncio.run_coroutine_threadsafe(update_status(), loop)

                    temp_images_path = manhwa_folder / (sanitize_filename(chapter['name']) + "_temp_cm")
                    temp_images_path.mkdir(exist_ok=True)

                    
                    image_urls = cm_get_chapter_image_urls(chapter['hid'], driver)
                    if not image_urls:
                        async def send_error():
                            await bot.send_message(chat_id=chat_id, text=f"âŒ ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                        asyncio.run_coroutine_threadsafe(send_error(), loop)
                        shutil.rmtree(temp_images_path)
                        continue

                    tasks = [(url, str(temp_images_path / f"{j+1:03d}{os.path.splitext(url.split('?')[0])[-1] or '.jpg'}")) for j, url in enumerate(image_urls)]
                    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                        executor.map(cm_download_single_image, tasks)

                    downloaded_files = sorted(os.listdir(temp_images_path))
                    if not downloaded_files:
                        async def send_dl_error():
                            await bot.send_message(chat_id=chat_id, text=f"âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
                        asyncio.run_coroutine_threadsafe(send_dl_error(), loop)
                        shutil.rmtree(temp_images_path)
                        continue

                    if create_zip:
                        async def update_zipping_status():
                            await bot.edit_message_text(
                                chat_id=chat_id,
                                message_id=message_id_to_edit,
                                text=f"[{i+1}/{total_chapters}] ğŸ—œï¸ Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ: {chapter['name']}..."
                            )
                        asyncio.run_coroutine_threadsafe(update_zipping_status(), loop)

                        zip_path = manhwa_folder / f"{manhwa_title} - {sanitize_filename(chapter['name'])}.zip"
                        create_zip_from_folder(str(temp_images_path), str(zip_path))

                        async def upload_zip():
                            with open(zip_path, 'rb') as doc:
                                await bot.send_document(chat_id=chat_id, document=doc, caption=zip_path.name)
                            os.remove(zip_path)
                        asyncio.run_coroutine_threadsafe(upload_zip(), loop)
                    else:
                        for img_file in downloaded_files:
                            async def upload_photo():
                                with open(temp_images_path / img_file, 'rb') as photo:
                                    await bot.send_photo(chat_id=chat_id, photo=photo, caption=img_file)
                            asyncio.run_coroutine_threadsafe(upload_photo(), loop)
                    
                    shutil.rmtree(temp_images_path)
            finally:
                if driver:
                    driver.quit()

        try:
            loop = asyncio.get_running_loop()
            await asyncio.to_thread(_download_all_chapters_sync, loop)

            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id_to_edit,
                text=f"âœ… ØªÙ…Ø§Ù… Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ '{manhwa_title}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯."
            )
        except Exception as e:
            logger.error(f"Celery Comick Task Error: {e}", exc_info=True)
            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id_to_edit,
                text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø® Ø¯Ø§Ø¯: {e}"
            )

    asyncio.run(_async_worker())


@cooldown_decorator()
async def handle_comick_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    url = update.message.text.strip()
    user_id = update.effective_user.id
    is_allowed, message_text = await check_subscription(user_id, COMICK_DOMAIN)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END

    message = await update.message.reply_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {COMICK_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø± Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú©...")
    
    def _sync_get_info(comic_url):
        driver = None
        try:
            driver = setup_firefox_driver()
            if not driver:
                return None, []
            
            return cm_get_info_and_chapters(comic_url, driver)
        finally:
            if driver:
                driver.quit()

    title, chapters = await asyncio.to_thread(_sync_get_info, url)

    if not chapters:
        await message.edit_text("Ù‡ÛŒÚ† Ú†Ù¾ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯.")
        return ConversationHandler.END
    
    context.user_data['cm_chapters'] = chapters
    context.user_data['cm_title'] = title
    context.user_data['cm_selected_indices'] = []
    context.user_data['cm_current_page'] = 0
    
    keyboard = create_chapter_keyboard(chapters, [], 0, "cm")
    await message.edit_text(
        f"âœ… {len(chapters)} Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ '{title}' ÛŒØ§ÙØª Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        reply_markup=keyboard
    )
    return CM_SELECTING_CHAPTERS

async def chapter_selection_cm_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    data = query.data
    chapters = context.user_data.get('cm_chapters', [])
    selected_indices = context.user_data.get('cm_selected_indices', [])
    page = context.user_data.get('cm_current_page', 0)
    
    if data.startswith("cm_toggle_"):
        index = int(data.split('_')[-1])
        if index in selected_indices:
            selected_indices.remove(index)
        else:
            selected_indices.append(index)
    elif data.startswith("cm_page_"):
        page = int(data.split('_')[-1])
    elif data == "cm_select_all":
        selected_indices = list(range(len(chapters)))
    elif data == "cm_deselect_all":
        selected_indices = []
    elif data == "cm_start_download":
        if not selected_indices:
            await query.answer("Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù‚Ø³Ù…Øª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.", show_alert=True)
            return CM_SELECTING_CHAPTERS
        keyboard = [
            [InlineKeyboardButton("Ø¨Ù„Ù‡ØŒ ÙØ§ÛŒÙ„ ZIP Ø¨Ø³Ø§Ø²", callback_data="cm_zip_yes")],
            [InlineKeyboardButton("Ù†Ù‡ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª", callback_data="cm_zip_no")]
        ]
        await query.edit_message_text(
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÙØ´Ø±Ø¯Ù‡ (ZIP) Ø´ÙˆÙ†Ø¯ØŸ",
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
        return CM_AWAIT_ZIP_OPTION
        
    context.user_data['cm_selected_indices'] = selected_indices
    context.user_data['cm_current_page'] = page
    keyboard = create_chapter_keyboard(chapters, selected_indices, page, "cm")
    await query.edit_message_reply_markup(reply_markup=keyboard)
    return CM_SELECTING_CHAPTERS


async def process_comick_download(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    
    create_zip = (query.data == 'cm_zip_yes')
    chapters_data = context.user_data.get('cm_chapters', [])
    manhwa_title = context.user_data.get('cm_title', 'Unknown')
    selected_indices = context.user_data.get('cm_selected_indices', [])
    
    if not all([chapters_data, manhwa_title, selected_indices is not None]):
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return ConversationHandler.END

    chapters_to_download = [chapters_data[i] for i in sorted(selected_indices)]

    
    process_comick_task.delay(
        chat_id=query.message.chat.id,
        manhwa_title=manhwa_title,
        chapters_to_download=chapters_to_download,
        create_zip=create_zip
    )

    await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(chapters_to_download)} Ù‚Ø³Ù…Øª Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    
    for key in list(context.user_data.keys()):
        if key.startswith('cm_'):
            context.user_data.pop(key)
            
    return ConversationHandler.END


@celery_app.task(name="tasks.process_manhwaclan")
def process_manhwaclan_task(chat_id: int, manhwa_title: str, chapters_to_download: list, create_zip: bool):
    """
    Celery task to download chapters from ManhwaClan.
    This runs in the background on a Celery worker.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(
            chat_id=chat_id, 
            text=f"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ '{manhwa_title}' Ø§Ø² ØµÙ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯..."
        )
        message_id_to_edit = status_message.message_id

        manhwa_folder = Path(DOWNLOAD_FOLDER) / sanitize_filename(manhwa_title)
        manhwa_folder.mkdir(parents=True, exist_ok=True)

        try:
            total_chapters = len(chapters_to_download)
            for i, chapter in enumerate(chapters_to_download):
                await bot.edit_message_text(
                    chat_id=chat_id, 
                    message_id=message_id_to_edit, 
                    text=f"[{i+1}/{total_chapters}] ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {chapter['name']}..."
                )
                
                temp_images_path = manhwa_folder / (sanitize_filename(chapter['name']) + "_temp_mc")
                temp_images_path.mkdir(exist_ok=True)

                # Run blocking network calls in a thread
                image_urls = await asyncio.to_thread(mc_get_chapter_image_urls, chapter['url'])

                if not image_urls:
                    await bot.send_message(chat_id=chat_id, text=f"âŒ ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    shutil.rmtree(temp_images_path)
                    continue

                def _download_images_sync():
                    tasks = [(url, str(temp_images_path / f"{j+1:03d}{os.path.splitext(url)[1].split('?')[0] or '.jpg'}")) for j, url in enumerate(image_urls)]
                    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                        executor.map(mc_download_single_image, tasks)
                
                await asyncio.to_thread(_download_images_sync)

                downloaded_files = sorted(os.listdir(temp_images_path))
                if not downloaded_files:
                    await bot.send_message(chat_id=chat_id, text=f"âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
                    shutil.rmtree(temp_images_path)
                    continue

                if create_zip:
                    await bot.edit_message_text(
                        chat_id=chat_id, 
                        message_id=message_id_to_edit, 
                        text=f"[{i+1}/{total_chapters}] ğŸ—œï¸ Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ: {chapter['name']}..."
                    )
                    
                    zip_path = manhwa_folder / f"{manhwa_title} - {sanitize_filename(chapter['name'])}.zip"
                    await asyncio.to_thread(create_zip_from_folder, str(temp_images_path), str(zip_path))
                    
                    with open(zip_path, 'rb') as doc:
                        await bot.send_document(chat_id=chat_id, document=doc, caption=zip_path.name)
                    os.remove(zip_path)
                else:
                    await bot.edit_message_text(
                        chat_id=chat_id, 
                        message_id=message_id_to_edit, 
                        text=f"[{i+1}/{total_chapters}] ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ {len(downloaded_files)} Ø¹Ú©Ø³..."
                    )
                    for img_file in downloaded_files:
                        with open(temp_images_path / img_file, 'rb') as photo:
                            await bot.send_photo(chat_id=chat_id, photo=photo, caption=img_file)
                
                shutil.rmtree(temp_images_path)

            await bot.edit_message_text(
                chat_id=chat_id, 
                message_id=message_id_to_edit, 
                text=f"âœ… ØªÙ…Ø§Ù… Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ '{manhwa_title}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯."
            )
        except Exception as e:
            logger.error(f"Celery ManhwaClan Task Error: {e}", exc_info=True)
            await bot.edit_message_text(
                chat_id=chat_id, 
                message_id=message_id_to_edit, 
                text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø® Ø¯Ø§Ø¯: {e}"
            )

    asyncio.run(_async_worker())

@cooldown_decorator()
async def handle_manhwaclan_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    url = update.message.text.strip()
    user_id = update.effective_user.id
    is_allowed, message_text = await check_subscription(user_id, MANHWACLAN_DOMAIN)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END

    message = await update.message.reply_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {MANHWACLAN_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú©...")
    
    
    chapters, title = await asyncio.to_thread(mc_get_chapters_and_title, url)
    
    if not chapters:
        await message.edit_text("Ù‡ÛŒÚ† Ú†Ù¾ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯.")
        return ConversationHandler.END
    
    context.user_data['mc_chapters'] = chapters
    context.user_data['mc_title'] = title
    context.user_data['mc_selected_indices'] = []
    context.user_data['mc_current_page'] = 0
    
    keyboard = create_chapter_keyboard(chapters, [], 0, "mc")
    await message.edit_text(
        f"âœ… {len(chapters)} Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ '{title}' ÛŒØ§ÙØª Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        reply_markup=keyboard
    )
    return MC_SELECTING_CHAPTERS

async def chapter_selection_mc_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    data = query.data
    chapters = context.user_data.get('mc_chapters', [])
    selected_indices = context.user_data.get('mc_selected_indices', [])
    page = context.user_data.get('mc_current_page', 0)

    if data.startswith("mc_toggle_"):
        index = int(data.split('_')[-1])
        if index in selected_indices:
            selected_indices.remove(index)
        else:
            selected_indices.append(index)
    elif data.startswith("mc_page_"):
        page = int(data.split('_')[-1])
    elif data == "mc_select_all":
        selected_indices = list(range(len(chapters)))
    elif data == "mc_deselect_all":
        selected_indices = []
    elif data == "mc_start_download":
        if not selected_indices:
            await query.answer("Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù‚Ø³Ù…Øª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.", show_alert=True)
            return MC_SELECTING_CHAPTERS
        keyboard = [
            [InlineKeyboardButton("Ø¨Ù„Ù‡ØŒ ÙØ§ÛŒÙ„ ZIP Ø¨Ø³Ø§Ø²", callback_data="mc_zip_yes")],
            [InlineKeyboardButton("Ù†Ù‡ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª", callback_data="mc_zip_no")]
        ]
        await query.edit_message_text(
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÙØ´Ø±Ø¯Ù‡ (ZIP) Ø´ÙˆÙ†Ø¯ØŸ",
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
        return MC_AWAIT_ZIP_OPTION
        
    context.user_data['mc_selected_indices'] = selected_indices
    context.user_data['mc_current_page'] = page
    keyboard = create_chapter_keyboard(chapters, selected_indices, page, "mc")
    await query.edit_message_reply_markup(reply_markup=keyboard)
    return MC_SELECTING_CHAPTERS


async def process_manhwaclan_download(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    
    create_zip = (query.data == 'mc_zip_yes')
    chapters_data = context.user_data.get('mc_chapters', [])
    manhwa_title = context.user_data.get('mc_title', 'Unknown')
    selected_indices = context.user_data.get('mc_selected_indices', [])
    
    if not all([chapters_data, manhwa_title, selected_indices is not None]):
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return ConversationHandler.END

    chapters_to_download = [chapters_data[i] for i in sorted(selected_indices)]

    
    process_manhwaclan_task.delay(
        chat_id=query.message.chat.id,
        manhwa_title=manhwa_title,
        chapters_to_download=chapters_to_download,
        create_zip=create_zip
    )

    await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(chapters_to_download)} Ù‚Ø³Ù…Øª Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    
    for key in list(context.user_data.keys()):
        if key.startswith('mc_'):
            context.user_data.pop(key)
            
    return ConversationHandler.END


@celery_app.task(name="tasks.process_toonily_me")
def process_toonily_me_task(chat_id: int, manhwa_title: str, chapters_to_download: list, create_zip: bool):
    
    
    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(chat_id=chat_id, text=f"ğŸ“¥ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(chapters_to_download)} Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ '{manhwa_title}' Ø§Ø² ØµÙ...")
        message_id_to_edit = status_message.message_id

        manhwa_folder = Path(DOWNLOAD_FOLDER) / sanitize_filename(manhwa_title)
        
        await asyncio.to_thread(manhwa_folder.mkdir, parents=True, exist_ok=True)
        
        try:
            total_chapters = len(chapters_to_download)
            for i, chapter in enumerate(chapters_to_download):
                await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"[{i+1}/{total_chapters}] ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {chapter['name']}...")
                
                temp_images_path = manhwa_folder / (sanitize_filename(chapter['name']) + "_temp_me")
                await asyncio.to_thread(temp_images_path.mkdir, exist_ok=True)

                
                image_urls = await asyncio.to_thread(mn2_get_chapter_images, chapter['url'])

                if not image_urls:
                    await bot.send_message(chat_id=chat_id, text=f"âŒ ØªØµÙˆÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                    await asyncio.to_thread(shutil.rmtree, temp_images_path)
                    continue
                
                
                def download_all_images():
                    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                        futures = [executor.submit(mn2_download_image, url, temp_images_path / f"{j+1:03d}.jpg") for j, url in enumerate(image_urls)]
                        concurrent.futures.wait(futures)
                
                await asyncio.to_thread(download_all_images)

                downloaded_files = await asyncio.to_thread(lambda: [f for f in os.listdir(temp_images_path) if f.endswith('.jpg')])
                if not downloaded_files:
                    await bot.send_message(chat_id=chat_id, text=f"âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
                    await asyncio.to_thread(shutil.rmtree, temp_images_path)
                    continue

                if create_zip:
                    await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"[{i+1}/{total_chapters}] ğŸ—œï¸ Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ...")
                    zip_path = manhwa_folder / f"{manhwa_title} - {chapter['name']}.zip"
                    await asyncio.to_thread(mn2_create_zip, downloaded_files, zip_path, temp_images_path, del_source=True)
                    
                    with open(zip_path, 'rb') as doc:
                        await bot.send_document(chat_id=chat_id, document=doc, caption=zip_path.name)
                    
                    await asyncio.to_thread(os.remove, zip_path)
                else:
                    await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"[{i+1}/{total_chapters}] ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ {len(downloaded_files)} Ø¹Ú©Ø³...")
                    for img_file in sorted(downloaded_files):
                        with open(temp_images_path / img_file, 'rb') as photo:
                            await bot.send_photo(chat_id=chat_id, photo=photo)
                    await asyncio.to_thread(shutil.rmtree, temp_images_path)
            
            await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"âœ… ØªÙ…Ø§Ù… Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ '{manhwa_title}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
        except Exception as e:
            logger.error(f"Celery Toonily.me Error: {e}", exc_info=True)
            await bot.edit_message_text(chat_id=chat_id, message_id=message_id_to_edit, text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø® Ø¯Ø§Ø¯: {e}")
    
    
    asyncio.run(_async_worker())


@cooldown_decorator()
async def start_manhwa_me_search(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    
    user_id = update.effective_user.id
    domain = TOONILY_ME_DOMAIN
    is_allowed, message_text = await check_subscription(user_id, domain)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END
    await update.message.reply_text(f"Ù„Ø·ÙØ§Ù‹ Ù†Ø§Ù… Ù…Ø§Ù†Ù‡ÙˆØ§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± {TOONILY_ME_DOMAIN} ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")
    return ME_AWAIT_MANHWA_SEARCH

async def receive_manhwa_me_search(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.message.text
    message = await update.message.reply_text(f"Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ '{query}'...")
    search_results = await asyncio.to_thread(mn2_search, query)
    if not search_results:
        await message.edit_text("Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ /cancel Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯.")
        return ME_AWAIT_MANHWA_SEARCH
    context.user_data['mn2_search_results'] = search_results
    keyboard = [[InlineKeyboardButton(result['name'], callback_data=f"mn2_select_{i}")] for i, result in enumerate(search_results[:10])]
    await message.edit_text("Ù†ØªØ§ÛŒØ¬ ÛŒØ§ÙØª Ø´Ø¯Ù‡:", reply_markup=InlineKeyboardMarkup(keyboard))
    return ME_SELECTING_MANHWA

async def _internal_show_me_chapters(update: Update, context: ContextTypes.DEFAULT_TYPE, url: str, message_to_edit) -> int:
    chapters, title = await asyncio.to_thread(mn2_get_chapters, url)
    if not chapters:
        await message_to_edit.edit_text("Ù‡ÛŒÚ† Ú†Ù¾ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© ÛŒØ§ÙØª Ù†Ø´Ø¯."); return ConversationHandler.END
    context.user_data['mn2_chapters'] = chapters
    context.user_data['mn2_title'] = title
    context.user_data['mn2_selected_indices'] = []
    context.user_data['mn2_current_page'] = 0
    keyboard = create_chapter_keyboard(chapters, [], 0, "mn2")
    await message_to_edit.edit_text(
        f"âœ… {len(chapters)} Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ '{title}' ÛŒØ§ÙØª Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
        reply_markup=keyboard
    )
    return ME_SELECTING_CHAPTERS

@cooldown_decorator()
async def handle_manhwa_me_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    
    if not update.message or not update.message.text: 
        return ConversationHandler.END
    url = update.message.text.strip()
    user_id = update.effective_user.id
    domain = TOONILY_ME_DOMAIN
    is_allowed, message_text = await check_subscription(user_id, domain)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END
    message = await update.message.reply_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {TOONILY_ME_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú© Ù…Ø³ØªÙ‚ÛŒÙ…...")
    return await _internal_show_me_chapters(update, context, url, message)

async def select_manhwa_me_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    index = int(query.data.split('_')[-1])
    search_results = context.user_data.get('mn2_search_results')
    if not search_results or index >= len(search_results):
        await query.edit_message_text("Ø®Ø·Ø§: Ù†ØªØ§ÛŒØ¬ Ø¬Ø³ØªØ¬Ùˆ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
        return ConversationHandler.END
    selected_manhwa = search_results[index]
    await query.edit_message_text(f"Ø´Ù…Ø§ '{selected_manhwa['name']}' Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯ÛŒØ¯. Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ú†Ù¾ØªØ±Ù‡Ø§...")
    return await _internal_show_me_chapters(update, context, selected_manhwa['url'], query.message)

async def chapter_selection_me_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    data = query.data
    chapters = context.user_data.get('mn2_chapters', [])
    selected_indices = context.user_data.get('mn2_selected_indices', [])
    page = context.user_data.get('mn2_current_page', 0)
    if data.startswith("mn2_toggle_"):
        index = int(data.split('_')[-1])
        if index in selected_indices: selected_indices.remove(index)
        else: selected_indices.append(index)
    elif data.startswith("mn2_page_"):
        page = int(data.split('_')[-1])
    elif data == "mn2_select_all":
        selected_indices = list(range(len(chapters)))
    elif data == "mn2_deselect_all":
        selected_indices = []
    elif data == "mn2_start_download":
        if not selected_indices:
            await context.bot.answer_callback_query(query.id, "Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù‚Ø³Ù…Øª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.", show_alert=True)
            return ME_SELECTING_CHAPTERS
        keyboard = [[InlineKeyboardButton("Ø¨Ù„Ù‡ØŒ ÙØ§ÛŒÙ„ ZIP Ø¨Ø³Ø§Ø²", callback_data="mn2_zip_yes")], [InlineKeyboardButton("Ù†Ù‡ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª", callback_data="mn2_zip_no")]]
        await query.edit_message_text("Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÙØ´Ø±Ø¯Ù‡ (ZIP) Ø´ÙˆÙ†Ø¯ØŸ", reply_markup=InlineKeyboardMarkup(keyboard))
        return ME_AWAIT_ZIP_OPTION
    context.user_data['mn2_selected_indices'] = selected_indices
    context.user_data['mn2_current_page'] = page
    keyboard = create_chapter_keyboard(chapters, selected_indices, page, "mn2")
    await query.edit_message_reply_markup(reply_markup=keyboard)
    return ME_SELECTING_CHAPTERS

async def process_manhwa_me_download(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    
    create_zip = (query.data == 'mn2_zip_yes')
    chapters_data = context.user_data.get('mn2_chapters', [])
    manhwa_title = context.user_data.get('mn2_title', 'Unknown')
    selected_indices = context.user_data.get('mn2_selected_indices', [])
    
    if not all([chapters_data, manhwa_title, selected_indices is not None]):
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return ConversationHandler.END

    chapters_to_download = [chapters_data[i] for i in sorted(selected_indices)]

    
    process_toonily_me_task.delay(
        chat_id=query.message.chat.id,
        manhwa_title=manhwa_title,
        chapters_to_download=chapters_to_download,
        create_zip=create_zip
    )

    await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(chapters_to_download)} Ù‚Ø³Ù…Øª Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    
    for key in list(context.user_data.keys()):
        if key.startswith('mn2_'):
            context.user_data.pop(key)
            
    return ConversationHandler.END


@celery_app.task(name="tasks.process_toonily_com")
def process_toonily_com_task(chat_id: int, manhwa_title: str, chapters_to_download: list, create_zip: bool):
    """
    Celery task to download chapters from Toonily.com using Selenium.
    This runs in the background on a Celery worker.
    """
    async def _async_worker():
        bot = get_bot_instance()
        status_message = await bot.send_message(
            chat_id=chat_id, 
            text=f"ğŸ“¥ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ '{manhwa_title}' Ø§Ø² ØµÙ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±..."
        )
        message_id_to_edit = status_message.message_id

        manhwa_folder = Path(DOWNLOAD_FOLDER) / sanitize_filename(manhwa_title)
        manhwa_folder.mkdir(parents=True, exist_ok=True)
        
        
        def _download_all_chapters_sync(loop): 
            driver = None
            try:
                driver = setup_driver()
                if not driver:
                    raise Exception("Failed to initialize Selenium driver.")
                
                total_chapters = len(chapters_to_download)
                for i, chapter in enumerate(chapters_to_download):
                    
                    async def update_status():
                        await bot.edit_message_text(
                            chat_id=chat_id, 
                            message_id=message_id_to_edit, 
                            text=f"[{i+1}/{total_chapters}] ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {chapter['name']}..."
                        )
                    
                    asyncio.run_coroutine_threadsafe(update_status(), loop)

                    downloaded_folder = download_images_for_chapter_sync_com(chapter, str(manhwa_folder), manhwa_title, driver)
                    
                    if not downloaded_folder or not os.listdir(downloaded_folder):
                        async def send_error():
                            await bot.send_message(chat_id=chat_id, text=f"âŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù‚Ø³Ù…Øª '{chapter['name']}' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ ÛŒØ§ ØªØµÙˆÛŒØ±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                        
                        asyncio.run_coroutine_threadsafe(send_error(), loop)
                        if downloaded_folder:
                             shutil.rmtree(downloaded_folder)
                        continue

                    if create_zip:
                        async def update_zipping_status():
                            await bot.edit_message_text(
                                chat_id=chat_id, 
                                message_id=message_id_to_edit, 
                                text=f"[{i+1}/{total_chapters}] ğŸ—œï¸ Ø¯Ø± Ø­Ø§Ù„ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ: {chapter['name']}..."
                            )
                        
                        asyncio.run_coroutine_threadsafe(update_zipping_status(), loop)
                        
                        zip_path = manhwa_folder / f"{manhwa_title} - {sanitize_filename(chapter['name'])}.zip"
                        create_zip_from_folder(downloaded_folder, str(zip_path))
                        
                        async def upload_zip():
                            with open(zip_path, 'rb') as doc:
                                await bot.send_document(chat_id=chat_id, document=doc, caption=zip_path.name)
                            os.remove(zip_path)
                        
                        asyncio.run_coroutine_threadsafe(upload_zip(), loop)

                    else:
                        async def update_upload_status():
                             await bot.edit_message_text(
                                chat_id=chat_id,
                                message_id=message_id_to_edit,
                                text=f"[{i+1}/{total_chapters}] ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ: {chapter['name']}..."
                            )
                        
                        asyncio.run_coroutine_threadsafe(update_upload_status(), loop)

                        image_files = sorted([os.path.join(downloaded_folder, f) for f in os.listdir(downloaded_folder)])
                        for img_path in image_files:
                            async def upload_photo():
                                with open(img_path, 'rb') as photo:
                                    await bot.send_photo(chat_id=chat_id, photo=photo, caption=os.path.basename(img_path))
                            
                            asyncio.run_coroutine_threadsafe(upload_photo(), loop)
                    
                    shutil.rmtree(downloaded_folder)

            finally:
                if driver:
                    driver.quit()

        try:
            
            loop = asyncio.get_running_loop()
            await asyncio.to_thread(_download_all_chapters_sync, loop)

            await bot.edit_message_text(
                chat_id=chat_id, 
                message_id=message_id_to_edit, 
                text=f"âœ… ØªÙ…Ø§Ù… Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ '{manhwa_title}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯."
            )
        except Exception as e:
            logger.error(f"Celery Toonily.com Task Error: {e}", exc_info=True)
            await bot.edit_message_text(
                chat_id=chat_id, 
                message_id=message_id_to_edit, 
                text=f"âŒ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø® Ø¯Ø§Ø¯: {e}"
            )

    asyncio.run(_async_worker())


@cooldown_decorator()
async def handle_toonily_com_link(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    url = update.message.text.strip()
    user_id = update.effective_user.id
    is_allowed, message_text = await check_subscription(user_id, TOONILY_COM_DOMAIN)
    if not is_allowed:
        await update.message.reply_text(message_text)
        return ConversationHandler.END

    message = await update.message.reply_text(f"Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: {TOONILY_COM_DOMAIN} | Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ùˆ ÛŒØ§ÙØªÙ† Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§...")
    
    
    def _sync_find_chapters():
        driver = None
        try:
            driver = setup_driver()
            if not driver:
                return None, None
            return find_all_chapters_com(url, driver)
        finally:
            if driver:
                driver.quit()

    chapters, manhwa_title = await asyncio.to_thread(_sync_find_chapters)
        
    if not chapters:
        await message.edit_text("Ù‡ÛŒÚ† Ù‚Ø³Ù…ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú© Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯.")
        return ConversationHandler.END
    
    adapted_chapters = [{'name': c['title'], 'url': c['url']} for c in chapters]
    
    context.user_data['com_chapters'] = adapted_chapters
    context.user_data['com_title'] = manhwa_title
    context.user_data['com_selected_indices'] = []
    context.user_data['com_current_page'] = 0
    
    keyboard = create_chapter_keyboard(adapted_chapters, [], 0, "com")
    await message.edit_text(
        f"âœ… {len(chapters)} Ù‚Ø³Ù…Øª Ø¨Ø±Ø§ÛŒ '{manhwa_title}' ÛŒØ§ÙØª Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ù‚Ø³Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", 
        reply_markup=keyboard
    )
    return COM_SELECTING_CHAPTERS

async def handle_chapter_selection_com(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    data = query.data
    chapters = context.user_data.get('com_chapters', [])
    selected_indices = context.user_data.get('com_selected_indices', [])
    page = context.user_data.get('com_current_page', 0)
    
    if data.startswith("com_toggle_"):
        index = int(data.split('_')[-1])
        if index in selected_indices:
            selected_indices.remove(index)
        else:
            selected_indices.append(index)
    elif data.startswith("com_page_"):
        page = int(data.split('_')[-1])
    elif data == "com_select_all":
        selected_indices = list(range(len(chapters)))
    elif data == "com_deselect_all":
        selected_indices = []
    elif data == "com_start_download":
        if not selected_indices:
            await query.answer("Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù‚Ø³Ù…Øª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.", show_alert=True)
            return COM_SELECTING_CHAPTERS
        keyboard = [
            [InlineKeyboardButton("Ø¨Ù„Ù‡ØŒ ÙØ§ÛŒÙ„ ZIP Ø¨Ø³Ø§Ø²", callback_data="com_zip_yes")],
            [InlineKeyboardButton("Ù†Ù‡ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª", callback_data="com_zip_no")]
        ]
        await query.edit_message_text(
            "Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ ÙØ´Ø±Ø¯Ù‡ (ZIP) Ø´ÙˆÙ†Ø¯ØŸ", 
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
        return COM_AWAIT_ZIP_OPTION
        
    context.user_data['com_selected_indices'] = selected_indices
    context.user_data['com_current_page'] = page
    keyboard = create_chapter_keyboard(chapters, selected_indices, page, "com")
    await query.edit_message_reply_markup(reply_markup=keyboard)
    return COM_SELECTING_CHAPTERS

async def process_toonily_com_download(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    
    create_zip = (query.data == 'com_zip_yes')
    chapters = context.user_data.get('com_chapters', [])
    manhwa_title = context.user_data.get('com_title', 'Unknown')
    selected_indices = context.user_data.get('com_selected_indices', [])

    if not all([chapters, manhwa_title, selected_indices is not None]):
        await query.edit_message_text("Ø®Ø·Ø§: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        return ConversationHandler.END

    chapters_to_download = [chapters[i] for i in sorted(selected_indices)]

    
    process_toonily_com_task.delay(
        chat_id=query.message.chat.id,
        manhwa_title=manhwa_title,
        chapters_to_download=chapters_to_download,
        create_zip=create_zip
    )

    await query.edit_message_text(f"âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ {len(chapters_to_download)} Ù‚Ø³Ù…Øª Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    
    for key in list(context.user_data.keys()):
        if key.startswith('com_'):
            context.user_data.pop(key)
            
    return ConversationHandler.END


async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    query = update.callback_query
    if query.data.startswith("yt_"):
        await yt_dlp_button_callback(update, context)



async def handle_yt_dlp_link(update: Update, context: ContextTypes.DEFAULT_TYPE, url: str):
    """
    Ù„ÛŒÙ†Ú© ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø±Ø¯Ù‡ Ùˆ Ù„ÛŒØ³Øª Ú©ÛŒÙÛŒØªâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
    """
    message = await update.message.reply_text("Ø¯Ø§Ù†Ù„ÙˆØ¯Ø±: yt-dlp | Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú©...")
    info = await asyncio.to_thread(get_full_video_info, url)
    if not info:
        await message.edit_text("Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª."); return
        
    context.user_data['video_info'] = info
    formats = [f for f in info.get('formats', []) if f.get('vcodec') != 'none' and f.get('height')]
    if not formats:
        await message.edit_text("Ù‡ÛŒÚ† Ú©ÛŒÙÛŒØª ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."); return
    
    best_formats = {}
    for f in formats:
        h = f.get('height')
        current_tbr = f.get('tbr') or 0
        if h not in best_formats or current_tbr > (best_formats[h].get('tbr') or 0):
            best_formats[h] = f
            
    keyboard = [
        [
            InlineKeyboardButton(
                f"{h}p ({(f.get('filesize') or f.get('filesize_approx') or 0) / (1024*1024):.2f} MB)",
                callback_data=f"yt_{f['format_id']}"
            )
        ]
        for h, f in sorted(best_formats.items(), reverse=True)
    ]
    keyboard.append([InlineKeyboardButton("Best Quality (Auto)", callback_data='yt_best')])
    await message.edit_text('Ú©ÛŒÙÛŒØª Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:', reply_markup=InlineKeyboardMarkup(keyboard))




def get_video_metadata(file_path: str) -> Tuple[int, int, int]:
    """
    (Synchronous Version)
    Extracts metadata (duration, width, height) from a video file using ffmpeg.
    This is a blocking function and should be run in a thread.
    """
    try:
        logger.info(f"Extracting metadata from: {file_path}")
        probe = ffmpeg.probe(file_path)
        video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)
        
        if not video_stream:
            logger.error("No video stream found in the file.")
            return 0, 0, 0
        
        duration = int(float(probe['format'].get('duration', 0)))
        width = int(video_stream.get('width', 0))
        height = int(video_stream.get('height', 0))
        
        logger.info(f"Metadata extracted: Duration={duration}s, Size={width}x{height}")
        return duration, width, height
        
    except (ffmpeg.Error, StopIteration, KeyError, ValueError) as e:
        logger.error(f"Error extracting metadata with ffmpeg: {e}", exc_info=True)
        return 0, 0, 0

async def upload_video_with_bot_api(
    bot: telegram.Bot,
    target_chat_id: int,
    file_path: str,
    thumb_path: str | None,
    caption: str,
    duration: int,
    width: int,
    height: int
) -> int | None:
    """
     ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ python-telegram-bot Ùˆ Ø³Ø±ÙˆØ± Ù…Ø­Ù„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    logger.info(f"[BotAPI] Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø± Ú†Øª {target_chat_id}: {file_path}")
    try:
        
        with open(file_path, "rb") as video_file:
            
            thumb_file_obj = open(thumb_path, "rb") if thumb_path and os.path.exists(thumb_path) else None
            try:
                message = await bot.send_video(
                    chat_id=target_chat_id,
                    video=video_file,
                    thumbnail=thumb_file_obj,
                    caption=caption,
                    duration=duration,
                    width=width,
                    height=height,
                    supports_streaming=True,
                    read_timeout=120,    
                    write_timeout=600    
                )
                logger.info(f"[BotAPI] ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯. Ø¢ÛŒØ¯ÛŒ Ù¾ÛŒØ§Ù…: {message.message_id}")
                return message.message_id
            finally:
                
                if thumb_file_obj:
                    thumb_file_obj.close()

    except TimedOut:
        logger.error("[BotAPI] Ø®Ø·Ø§: Ø²Ù…Ø§Ù† Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
        return None
    except NetworkError as e:
        logger.error(f"[BotAPI] Ø®Ø·Ø§ Ø¯Ø± Ø´Ø¨Ú©Ù‡ Ù‡Ù†Ú¯Ø§Ù… Ø¢Ù¾Ù„ÙˆØ¯: {e}")
        return None
    except Exception as e:
        logger.error(f"[BotAPI] Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø¢Ù¾Ù„ÙˆØ¯: {e}", exc_info=True)
        return None

def apply_watermark_to_video(video_path: str, settings: dict) -> str | None:
    """
    (Synchronous Version)
    Applies a watermark to the video based on user settings and returns the path to the output file.
    Returns None on error. This is a blocking function and should be run in a thread.
    """
    if not settings.get("enabled") or not settings.get("text"):
        logger.info("Watermark is disabled or has no text. Skipping.")
        return video_path  

    
    if not os.path.isfile(FONT_FILE):
        logger.error(f"Font file '{FONT_FILE}' not found! Cannot apply watermark.")
        return video_path 

    output_path = f"{os.path.splitext(video_path)[0]}_watermarked.mp4"
    
    position_map = {
        "top_left": "x=10:y=10",
        "top_right": "x=w-text_w-10:y=10",
        "bottom_left": "x=10:y=h-text_h-10",
        "bottom_right": "x=w-text_w-10:y=h-text_h-10",
    }
    position = position_map.get(settings.get("position", "top_left"), "x=10:y=10")

    escaped_text = settings['text'].replace("'", "'\\''").replace(":", "\\:").replace("\\", "\\\\")
    
    
    escaped_font_path = FONT_FILE.replace('\\', '/').replace(':', '\\:')
    
    font_size = int(settings.get("size", 32))
    font_color = settings.get("color", "white")
    border_w = int(settings.get("stroke", 2))

    video_filter = (
        f"drawtext=fontfile='{escaped_font_path}':"
        f"text='{escaped_text}':"
        f"fontcolor={font_color}:fontsize={font_size}:"
        f"{position}:"
        f"borderw={border_w}:bordercolor=black@0.6"
    )

    command = [
        'ffmpeg', '-y',
        '-i', video_path,
        '-vf', video_filter,
        '-codec:a', 'copy',
        output_path
    ]

    logger.info("Running synchronous FFmpeg watermark command...")
    logger.info(shlex.join(command))

    try:
        
        result = subprocess.run(
            command,
            capture_output=True, 
            text=True,           
            check=False          
        )

        if result.returncode != 0:
            logger.error(f"Error in FFmpeg during watermarking: {result.stderr}")
            return None 
        
        logger.info("Watermark applied successfully.")
        
        
        os.remove(video_path)
        os.rename(output_path, video_path)
        
        return video_path 

    except Exception as e:
        logger.error(f"An unexpected error occurred while running ffmpeg for watermarking: {e}", exc_info=True)
        return None

async def watermark_panel_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù¾Ù†Ù„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."""
    user_id = update.effective_user.id
    settings = get_user_watermark_settings(user_id)
    
    status_emoji = "âœ… (ÙØ¹Ø§Ù„)" if settings["enabled"] else "âŒ (ØºÛŒØ±ÙØ¹Ø§Ù„)"
    position_text_map = {
        "top_left": " Ø¨Ø§Ù„Ø§ Ú†Ù¾",
        "top_right": " Ø¨Ø§Ù„Ø§ Ø±Ø§Ø³Øª",
        "bottom_left": " Ù¾Ø§ÛŒÛŒÙ† Ú†Ù¾",
        "bottom_right": " Ù¾Ø§ÛŒÛŒÙ† Ø±Ø§Ø³Øª",
    }
    pos_text = position_text_map.get(settings["position"])
    
    text = (
        "âš™ï¸ **Ù¾Ù†Ù„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ§ØªØ±Ù…Ø§Ø±Ú©**\n\n"
        f"â–ªï¸ ÙˆØ¶Ø¹ÛŒØª: **{status_emoji}**\n"
        f"â–ªï¸ Ù…ØªÙ†: `{settings['text']}`\n"
        f"â–ªï¸ Ù…ÙˆÙ‚Ø¹ÛŒØª: **{pos_text}**\n"
        f"â–ªï¸ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙÙˆÙ†Øª: **{settings['size']}**\n"
        f"â–ªï¸ Ø±Ù†Ú¯ ÙÙˆÙ†Øª: **{settings['color']}**\n"
        f"â–ªï¸ Ø¶Ø®Ø§Ù…Øª Ø­Ø§Ø´ÛŒÙ‡ (Stroke): **{settings['stroke']}**\n"
    )
    
    keyboard = [
        [InlineKeyboardButton(f"ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª {status_emoji}", callback_data="wm_toggle")],
        [InlineKeyboardButton("ÙˆÛŒØ±Ø§ÛŒØ´ Ù…ØªÙ† ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© ğŸ“", callback_data="wm_set_text")],
        [
            InlineKeyboardButton(" Ù…ÙˆÙ‚Ø¹ÛŒØª", callback_data="wm_noop"),
            InlineKeyboardButton("ğŸ”¼", callback_data="wm_pos_top_left"),
            InlineKeyboardButton("ğŸ”¼", callback_data="wm_pos_top_right"),
        ],
        [
            InlineKeyboardButton(f"{pos_text}", callback_data="wm_noop"),
            InlineKeyboardButton("ğŸ”½", callback_data="wm_pos_bottom_left"),
            InlineKeyboardButton("ğŸ”½", callback_data="wm_pos_bottom_right"),
        ],
        [
             InlineKeyboardButton("â–", callback_data="wm_size_dec"),
             InlineKeyboardButton(f"Ø§Ù†Ø¯Ø§Ø²Ù‡: {settings['size']}", callback_data="wm_set_size"),
             InlineKeyboardButton("â•", callback_data="wm_size_inc"),
        ],
        [
             InlineKeyboardButton("â–", callback_data="wm_stroke_dec"),
             InlineKeyboardButton(f"Ø­Ø§Ø´ÛŒÙ‡: {settings['stroke']}", callback_data="wm_set_stroke"),
             InlineKeyboardButton("â•", callback_data="wm_stroke_inc"),
        ],
        [
            InlineKeyboardButton("âšªï¸", callback_data="wm_color_white"),
            InlineKeyboardButton("âš«ï¸", callback_data="wm_color_black"),
            InlineKeyboardButton("ğŸŸ¡", callback_data="wm_color_yellow"),
            InlineKeyboardButton("ğŸ”µ", callback_data="wm_color_blue"),
        ],
        [InlineKeyboardButton("Ø¨Ø³ØªÙ† Ù¾Ù†Ù„", callback_data="wm_close")]
    ]
    
    await update.message.reply_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
    return WATERMARK_PANEL


async def watermark_panel_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ù†Ù„ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    query = update.callback_query
    await query.answer()
    data = query.data.replace("wm_", "")
    user_id = query.from_user.id
    settings = get_user_watermark_settings(user_id)
    
    action_taken = True
    next_state = WATERMARK_PANEL

    if data == "toggle":
        settings["enabled"] = not settings["enabled"]
    elif data.startswith("pos_"):
        settings["position"] = data.replace("pos_", "")
    elif data.endswith("_inc") or data.endswith("_dec"):
        key, operation = data.rsplit('_', 1)
        current_value = settings.get(key, 0)
        increment = 5 if key == "size" else 1
        if operation == "inc":
            settings[key] = current_value + increment
        else:
            settings[key] = max(0, current_value - increment)
    elif data.startswith("color_"):
        settings["color"] = data.replace("color_", "")
    elif data == "set_text":
        await query.message.edit_text("Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø¬Ø¯ÛŒØ¯ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")
        return AWAIT_WATERMARK_TEXT
    elif data == "close":
        await query.message.delete()
        return ConversationHandler.END
    elif data == "noop":
        return WATERMARK_PANEL 
    else:
        action_taken = False

    if action_taken:
        update_user_watermark_settings(user_id, settings)
        
        status_emoji = "âœ… (ÙØ¹Ø§Ù„)" if settings["enabled"] else "âŒ (ØºÛŒØ±ÙØ¹Ø§Ù„)"
        position_text_map = {"top_left": " Ø¨Ø§Ù„Ø§ Ú†Ù¾", "top_right": " Ø¨Ø§Ù„Ø§ Ø±Ø§Ø³Øª", "bottom_left": " Ù¾Ø§ÛŒÛŒÙ† Ú†Ù¾", "bottom_right": " Ù¾Ø§ÛŒÛŒÙ† Ø±Ø§Ø³Øª"}
        pos_text = position_text_map.get(settings["position"])
        text = (f"âš™ï¸ **Ù¾Ù†Ù„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ§ØªØ±Ù…Ø§Ø±Ú©**\n\n"
                f"â–ªï¸ ÙˆØ¶Ø¹ÛŒØª: **{status_emoji}**\nâ–ªï¸ Ù…ØªÙ†: `{settings['text']}`\n"
                f"â–ªï¸ Ù…ÙˆÙ‚Ø¹ÛŒØª: **{pos_text}**\nâ–ªï¸ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙÙˆÙ†Øª: **{settings['size']}**\n"
                f"â–ªï¸ Ø±Ù†Ú¯ ÙÙˆÙ†Øª: **{settings['color']}**\nâ–ªï¸ Ø¶Ø®Ø§Ù…Øª Ø­Ø§Ø´ÛŒÙ‡ (Stroke): **{settings['stroke']}**\n")
        keyboard = [[InlineKeyboardButton(f"ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª {status_emoji}", callback_data="wm_toggle")],
                    [InlineKeyboardButton("ÙˆÛŒØ±Ø§ÛŒØ´ Ù…ØªÙ† ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© ğŸ“", callback_data="wm_set_text")],
                    [InlineKeyboardButton(" Ù…ÙˆÙ‚Ø¹ÛŒØª", callback_data="wm_noop"), InlineKeyboardButton("ğŸ”¼", callback_data="wm_pos_top_left"), InlineKeyboardButton("ğŸ”¼", callback_data="wm_pos_top_right")],
                    [InlineKeyboardButton(f"{pos_text}", callback_data="wm_noop"), InlineKeyboardButton("ğŸ”½", callback_data="wm_pos_bottom_left"), InlineKeyboardButton("ğŸ”½", callback_data="wm_pos_bottom_right")],
                    [InlineKeyboardButton("â–", callback_data="wm_size_dec"), InlineKeyboardButton(f"Ø§Ù†Ø¯Ø§Ø²Ù‡: {settings['size']}", callback_data="wm_set_size"), InlineKeyboardButton("â•", callback_data="wm_size_inc")],
                    [InlineKeyboardButton("â–", callback_data="wm_stroke_dec"), InlineKeyboardButton(f"Ø­Ø§Ø´ÛŒÙ‡: {settings['stroke']}", callback_data="wm_set_stroke"), InlineKeyboardButton("â•", callback_data="wm_stroke_inc")],
                    [InlineKeyboardButton("âšªï¸", callback_data="wm_color_white"), InlineKeyboardButton("âš«ï¸", callback_data="wm_color_black"), InlineKeyboardButton("ğŸŸ¡", callback_data="wm_color_yellow"), InlineKeyboardButton("ğŸ”µ", callback_data="wm_color_blue")],
                    [InlineKeyboardButton("Ø¨Ø³ØªÙ† Ù¾Ù†Ù„", callback_data="wm_close")]]
        await query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode='Markdown')
        
    return next_state

async def await_watermark_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù…ØªÙ† Ø¬Ø¯ÛŒØ¯ ÙˆØ§ØªØ±Ù…Ø§Ø±Ú© Ø±Ø§ Ø§Ø² Ú©Ø§Ø±Ø¨Ø± Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    user_id = update.effective_user.id
    new_text = update.message.text
    
    settings = get_user_watermark_settings(user_id)
    settings["text"] = new_text
    update_user_watermark_settings(user_id, settings)
    
    await update.message.delete() 
    
    await watermark_panel_command(update, context) 
    return WATERMARK_PANEL


async def yt_dlp_button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    selected_format = query.data.split("_", 1)[1]
    info = context.user_data.get('video_info')
    if not info:
        await query.edit_message_text(text="Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù„ÛŒÙ†Ú© Ø±Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯.")
        return
        
    url = info.get('webpage_url')
    user_id = query.from_user.id

    
    video_info_json = json.dumps(info)

   
    download_and_upload_video_task.delay(
        chat_id=query.message.chat.id,
        url=url,
        selected_format=selected_format,
        video_info_json=video_info_json, 
        user_id=user_id
    )
    
    await query.edit_message_text("âœ… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")
    context.user_data.pop('video_info', None)


async def set_thumbnail_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    await update.message.reply_text("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ø¹Ú©Ø³ Ø¨Ø±Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ ÛŒØ§ /cancel Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯.")
    return AWAIT_THUMBNAIL

async def receive_thumbnail(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    set_user_thumbnail(update.effective_user.id, update.message.photo[-1].file_id)
    await update.message.reply_text("âœ… ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯!")
    return ConversationHandler.END

async def cancel_conversation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    
    if 'gdl_download_path' in context.user_data:
        download_path = context.user_data['gdl_download_path']
        if os.path.exists(download_path):
            shutil.rmtree(download_path)
        
    for key in list(context.user_data.keys()):
        if key.startswith(('com_', 'mn2_', 'mc_', 'md_', 'ct_', 'cm_', 'gdl_')):
            del context.user_data[key]
            
    await update.message.reply_text("Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.")
    return ConversationHandler.END



async def check_subscription(user_id: int, domain: str) -> Tuple[bool, str]:
    """
    ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù…Ù„ Ø§Ø´ØªØ±Ø§Ú© Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    user_data = get_user_data(user_id)
    if user_data.get('is_admin', False):
        return True, "Admin access granted."

    sub = user_data.get('subscription', {})
    
    
    if not sub.get('is_active', False):
        return False, "Your subscription is not active. Please subscribe to use the bot."

    
    expiry_date_str = sub.get('expiry_date')
    if expiry_date_str:
        try:
            if datetime.fromisoformat(expiry_date_str) < datetime.now():
                user_data['subscription']['is_active'] = False
                update_user_data(user_id, user_data)
                return False, "Your subscription has expired. Please renew it."
        except (ValueError, TypeError):
            user_data['subscription']['is_active'] = False
            update_user_data(user_id, user_data)
            return False, "Subscription data error. Please contact support."

    
    limit = sub.get('download_limit', -1)
    if limit != -1:
        stats = user_data.get('stats', {})
        downloads_today_data = stats.get('downloads_today', {})
        today_str = str(datetime.now().date())
        
        downloads_today_count = downloads_today_data.get('count', 0) if downloads_today_data.get('date') == today_str else 0
        if downloads_today_count >= limit:
            return False, f"You have reached your daily download limit of {limit} files."

    
    all_sites_flat = [site for category_sites in ALL_SUPPORTED_SITES.values() for site in category_sites]
    if domain in all_sites_flat:
        
        if not sub.get('allowed_sites', {}).get(domain, False):
            return False, f"Your subscription does not include access to {domain}."
    
    return True, "Access granted."

async def admin_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """[Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ] Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ† Ú©Ù‡ Ù‡Ù… Ø¨Ø§ Ø¯Ø³ØªÙˆØ± Ùˆ Ù‡Ù… Ø¨Ø§ Ø¯Ú©Ù…Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    user_id = update.effective_user.id
    
    chat = update.effective_chat

    if not chat:
        
        return ConversationHandler.END

    if user_id not in ADMIN_IDS:
        await chat.send_message("Ø´Ù…Ø§ Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return ConversationHandler.END

    keyboard = [
        ["ğŸ“Š Ø¢Ù…Ø§Ø±", "ğŸ“¢ Ù‡Ù…Ú¯Ø§Ù†ÛŒ"],
        ["âš™ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø´ØªØ±Ø§Ú©", "ğŸ“ Ù…ØªÙ† Ù‡Ø§"],
        ["âŒ Ø®Ø±ÙˆØ¬ Ø§Ø² Ù¾Ù†Ù„"]
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    
    
    if update.callback_query:
        try:
            await update.callback_query.message.delete()
        except Exception:
            pass 

    
    await chat.send_message("Ø¨Ù‡ Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ† Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.", reply_markup=reply_markup)
    return ADMIN_PANEL

async def show_stats(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø±Ø¨Ø§Øª Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."""
    db = load_user_db()
    total_users = len(db)
    today_str = str(datetime.now().date())
    
    downloads_today = 0
    active_subs = 0
    expired_subs = 0
    site_usage = {}

    for user_id, data in db.items():
        if not isinstance(data, dict): continue
        
        if data.get('stats', {}).get('downloads_today', {}).get('date') == today_str:
            downloads_today += data['stats']['downloads_today'].get('count', 0)
        
        if data.get('subscription', {}).get('is_active'):
            expiry_date_str = data['subscription'].get('expiry_date')
            if expiry_date_str:
                try:
                    if datetime.fromisoformat(expiry_date_str) > datetime.now():
                        active_subs += 1
                    else:
                        expired_subs += 1
                except (ValueError, TypeError):
                    expired_subs += 1
            else:
                active_subs += 1
        
        for site, count in data.get('stats', {}).get('site_usage', {}).items():
            site_usage[site] = site_usage.get(site, 0) + count

    top_sites = sorted(site_usage.items(), key=lambda item: item[1], reverse=True)[:3]
    top_sites_text = "\n".join([f"â€¢ {site}" for site, count in top_sites]) if top_sites else "No data recorded"

    stats_text = (
        "ğŸ“Š **Bot Statistics**\n\n"
        "ğŸ‘¥ **Users**\n"
        f"â€¢ Total Users: {total_users}\n"
        f"â€¢ Downloads (Today): {downloads_today}\n\n"
        "ğŸŒ **Most Popular Sites**\n"
        f"{top_sites_text}\n\n"
        "ğŸ’³ **Subscriptions**\n"
        f"â€¢ Active Subscriptions: {active_subs}\n"
        f"â€¢ Expired Subscriptions: {expired_subs}\n\n"
        f"@{BOT_USERNAME}"
    )
    await update.message.reply_text(stats_text, parse_mode='Markdown')
    return ADMIN_PANEL

async def broadcast_options(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ù… Ù‡Ù…Ú¯Ø§Ù†ÛŒ Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."""
    keyboard = [
        [InlineKeyboardButton("Send Text Message", callback_data="bc_text")],
        [InlineKeyboardButton("Forward Message", callback_data="bc_forward")],
        [InlineKeyboardButton("Back", callback_data="admin_back")]
    ]
    await update.message.reply_text("Please select the broadcast type:", reply_markup=InlineKeyboardMarkup(keyboard))
    return ADMIN_PANEL

async def await_broadcast_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù…Ù†ØªØ¸Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù‡Ù…Ú¯Ø§Ù†ÛŒ."""
    await update.callback_query.message.edit_text("Please enter the message to send to all users:")
    return AWAIT_BROADCAST_MESSAGE

async def send_broadcast_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    message = await update.message.reply_text("Preparing to send...")
    db = load_user_db()
    sent_count = 0
    failed_count = 0
    for user_id in db.keys():
        try:
            await context.bot.copy_message(chat_id=user_id, from_chat_id=update.message.chat_id, message_id=update.message.message_id)
            sent_count += 1
            await asyncio.sleep(0.1)
        except Exception:
            failed_count += 1
    
    await message.edit_text(f"âœ… Broadcast sent successfully to {sent_count} users.\nâŒ Failed to send to {failed_count} users.")
    return ADMIN_PANEL

async def await_broadcast_forward_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù…Ù†ØªØ¸Ø± ÙÙˆØ±ÙˆØ§Ø±Ø¯ ÛŒÚ© Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù‡Ù…Ú¯Ø§Ù†ÛŒ."""
    await update.callback_query.message.edit_text("Please forward the message you want to broadcast to everyone:")
    return AWAIT_BROADCAST_FORWARD

async def forward_broadcast_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù¾ÛŒØ§Ù… ÙÙˆØ±ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙÙˆØ±ÙˆØ§Ø±Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    message = await update.message.reply_text("Preparing to forward...")
    db = load_user_db()
    sent_count = 0
    failed_count = 0
    for user_id in db.keys():
        try:
            await context.bot.forward_message(chat_id=user_id, from_chat_id=update.message.chat_id, message_id=update.message.message_id)
            sent_count += 1
            await asyncio.sleep(0.1)
        except Exception:
            failed_count += 1
            
    await message.edit_text(f"âœ… Message forwarded successfully to {sent_count} users.\nâŒ Failed to forward to {failed_count} users.")
    return ADMIN_PANEL

async def ask_for_user_id(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ø§Ø² Ø§Ø¯Ù…ÛŒÙ†ØŒ Ø¢ÛŒØ¯ÛŒ Ø¹Ø¯Ø¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ù…ÛŒâ€ŒÙ¾Ø±Ø³Ø¯."""
    await update.message.reply_text("Please enter the User ID (UID) to manage their subscription:")
    return AWAIT_SUB_USER_ID



async def admin_cancel(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ø®Ø±ÙˆØ¬ Ø§Ø² Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ†."""
    await update.message.reply_text("You have exited the Admin Panel.", reply_markup=ReplyKeyboardRemove())
    return ConversationHandler.END

async def admin_sub_operation_cancel(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """
    Ø¹Ù…Ù„ÛŒØ§Øª ÙØ±Ø¹ÛŒ Ø¯Ø± Ù¾Ù†Ù„ Ø§Ø¯Ù…ÛŒÙ† Ø±Ø§ Ù„ØºÙˆ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø§Ø²Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯.
    """

    context.user_data.pop('target_user_id', None)
    
    await update.message.reply_text("Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯. Ø¨Ù‡ Ù¾Ù†Ù„ Ø§ØµÙ„ÛŒ Ø§Ø¯Ù…ÛŒÙ† Ø¨Ø§Ø²Ú¯Ø´ØªÛŒØ¯.")

    return await admin_command(update, context)


def main() -> None:

    if not check_dependencies(): 
        sys.exit(1)
    os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)
    

    application = (
    Application.builder()
    .token(BOT_TOKEN)
    .base_url("http://91.107.146.233:8081/bot")
    .base_file_url("http://91.107.146.233:8081/file/bot") 
    .build()
    )
    

    all_gallery_dl_sites = GALLERY_DL_SITES + GALLERY_DL_ZIP_SITES
    gallery_dl_sites_pattern = '|'.join([re.escape(site) for site in all_gallery_dl_sites])

    thumb_conv_handler = ConversationHandler(

         entry_points=[CommandHandler('thumb', set_thumbnail_command)],
         states={
             AWAIT_THUMBNAIL: [MessageHandler(filters.PHOTO, receive_thumbnail)]
         },
         fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )

    toonily_com_conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.TEXT & filters.Regex(TOONILY_COM_DOMAIN), handle_toonily_com_link)],
        states={
            COM_SELECTING_CHAPTERS: [CallbackQueryHandler(handle_chapter_selection_com, pattern="^com_")],
            COM_AWAIT_ZIP_OPTION: [CallbackQueryHandler(process_toonily_com_download, pattern="^com_zip_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )

    toonily_me_conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler('SearchToonily', start_manhwa_me_search),
            MessageHandler(filters.TEXT & filters.Regex(TOONILY_ME_DOMAIN), handle_manhwa_me_link)
        ],
        states={
            ME_AWAIT_MANHWA_SEARCH: [MessageHandler(filters.TEXT & ~filters.COMMAND, receive_manhwa_me_search)],
            ME_SELECTING_MANHWA: [CallbackQueryHandler(select_manhwa_me_callback, pattern="^mn2_select_")],
            ME_SELECTING_CHAPTERS: [CallbackQueryHandler(chapter_selection_me_callback, pattern="^mn2_")],
            ME_AWAIT_ZIP_OPTION: [CallbackQueryHandler(process_manhwa_me_download, pattern="^mn2_zip_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )

    manhwaclan_conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.TEXT & filters.Regex(MANHWACLAN_DOMAIN), handle_manhwaclan_link)],
        states={
            MC_SELECTING_CHAPTERS: [CallbackQueryHandler(chapter_selection_mc_callback, pattern="^mc_")],
            MC_AWAIT_ZIP_OPTION: [CallbackQueryHandler(process_manhwaclan_download, pattern="^mc_zip_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )

    mangadistrict_conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.TEXT & filters.Regex(MANGA_DISTRICT_DOMAIN), handle_mangadistrict_link)],
        states={
            MD_SELECTING_CHAPTERS: [CallbackQueryHandler(chapter_selection_md_callback, pattern="^md_")],
            MD_AWAIT_ZIP_OPTION: [CallbackQueryHandler(process_mangadistrict_download, pattern="^md_zip_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )
    cosplaytele_conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.TEXT & filters.Regex(COSPLAYTELE_DOMAIN), handle_cosplaytele_link)],
        states={
            CT_AWAIT_USER_CHOICE: [CallbackQueryHandler(process_cosplaytele_download, pattern="^ct_choice_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )
    comick_conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.TEXT & filters.Regex(COMICK_DOMAIN), handle_comick_link)],
        states={
            CM_SELECTING_CHAPTERS: [CallbackQueryHandler(chapter_selection_cm_callback, pattern="^cm_")],
            CM_AWAIT_ZIP_OPTION: [CallbackQueryHandler(process_comick_download, pattern="^cm_zip_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )
    gallery_dl_conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.TEXT & filters.Regex(gallery_dl_sites_pattern), handle_gallery_dl_link)],
        states={
            GALLERY_DL_AWAIT_ZIP_OPTION: [CallbackQueryHandler(process_gallery_dl_upload, pattern="^gdl_zip_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )


    erome_conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.TEXT & filters.Regex(EROME_DOMAIN), handle_erome_link)],
        states={
            EROME_AWAIT_CHOICE: [CallbackQueryHandler(process_erome_download, pattern="^er_choice_")],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )


    watermark_conv_handler = ConversationHandler(
        entry_points=[CommandHandler('water', watermark_panel_command)],
        states={
            WATERMARK_PANEL: [CallbackQueryHandler(watermark_panel_callback, pattern="^wm_")],
            AWAIT_WATERMARK_TEXT: [MessageHandler(filters.TEXT & ~filters.COMMAND, await_watermark_text)],
        },
        fallbacks=[CommandHandler('cancel', cancel_conversation)],
    )

    video_edit_conv_handler = ConversationHandler(
         entry_points=[MessageHandler(filters.VIDEO, handle_user_video)],
         states={
             AWAIT_VIDEO_CHOICE: [CallbackQueryHandler(process_video_edit_choice, pattern="^vid_edit_")],
         },
         fallbacks=[CommandHandler('cancel', cancel_conversation)],
         conversation_timeout=300 
    )


    admin_conv_handler = ConversationHandler(
        entry_points=[CommandHandler('admin', admin_command)],
        states={
            ADMIN_PANEL: [
                MessageHandler(filters.Regex('^ğŸ“Š Ø¢Ù…Ø§Ø±$'), show_stats),
                MessageHandler(filters.Regex('^ğŸ“¢ Ù‡Ù…Ú¯Ø§Ù†ÛŒ$'), broadcast_options),
                MessageHandler(filters.Regex('^âš™ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø´ØªØ±Ø§Ú©$'), ask_for_user_id),
                MessageHandler(filters.Regex('^ğŸ“ Ù…ØªÙ† Ù‡Ø§$'), texts_panel_command),
                MessageHandler(filters.Regex('^Ø±Ø§Ù‡Ù†Ù…Ø§$'), show_help_command), # <--- [Ø§ØµÙ„Ø§Ø­] Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                CallbackQueryHandler(await_broadcast_message_handler, pattern='^bc_text$'),
                CallbackQueryHandler(await_broadcast_forward_handler, pattern='^bc_forward$'),
                CallbackQueryHandler(admin_command, pattern='^admin_back$'),
            ],
            AWAIT_BROADCAST_MESSAGE: [
                CommandHandler('cancel', admin_sub_operation_cancel),
                MessageHandler(filters.TEXT & ~filters.COMMAND, send_broadcast_message)
            ],
            AWAIT_BROADCAST_FORWARD: [
                CommandHandler('cancel', admin_sub_operation_cancel),
                MessageHandler(filters.FORWARDED, forward_broadcast_message)
            ],
            AWAIT_SUB_USER_ID: [
                CommandHandler('cancel', admin_sub_operation_cancel),
                MessageHandler(filters.TEXT & ~filters.COMMAND, manage_subscription)
            ],
            MANAGE_USER_SUB: [
                CommandHandler('cancel', admin_sub_operation_cancel),
                MessageHandler(filters.Regex('^ğŸ“Š Ø¢Ù…Ø§Ø±$'), show_stats),
                MessageHandler(filters.Regex('^ğŸ“¢ Ù‡Ù…Ú¯Ø§Ù†ÛŒ$'), broadcast_options),
                MessageHandler(filters.Regex('^âš™ï¸ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø´ØªØ±Ø§Ú©$'), ask_for_user_id),
                MessageHandler(filters.Regex('^ğŸ“ Ù…ØªÙ† Ù‡Ø§$'), texts_panel_command),
                MessageHandler(filters.Regex('^Ø±Ø§Ù‡Ù†Ù…Ø§$'), show_help_command), # <--- [Ø§ØµÙ„Ø§Ø­] Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
                CallbackQueryHandler(manage_subscription_callback, pattern='^sub_')
            ],
            TEXTS_PANEL: [
                CallbackQueryHandler(texts_panel_callback, pattern='^texts_')
            ],
            AWAIT_HELP_TEXT: [
                CommandHandler('cancel', admin_sub_operation_cancel),
                MessageHandler(filters.TEXT & ~filters.COMMAND, await_help_text_handler)
            ]
        },
        fallbacks=[MessageHandler(filters.Regex('^âŒ Ø®Ø±ÙˆØ¬ Ø§Ø² Ù¾Ù†Ù„$'), admin_cancel), CommandHandler('cancel', admin_cancel)],
    )
    

    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(thumb_conv_handler)
    application.add_handler(toonily_com_conv_handler)
    application.add_handler(toonily_me_conv_handler)
    application.add_handler(manhwaclan_conv_handler)
    application.add_handler(mangadistrict_conv_handler)
    application.add_handler(cosplaytele_conv_handler)
    application.add_handler(comick_conv_handler)
    application.add_handler(gallery_dl_conv_handler)
    application.add_handler(erome_conv_handler)
    application.add_handler(watermark_conv_handler)
    application.add_handler(video_edit_conv_handler)
    application.add_handler(admin_conv_handler)
    
    general_link_filter = (
        filters.TEXT & 
        filters.Entity("url") &
        ~filters.COMMAND & 
        ~filters.Regex(TOONILY_COM_DOMAIN) & 
        ~filters.Regex(TOONILY_ME_DOMAIN) &
        ~filters.Regex(MANHWACLAN_DOMAIN) &
        ~filters.Regex(MANGA_DISTRICT_DOMAIN) &
        ~filters.Regex(COSPLAYTELE_DOMAIN) &
        ~filters.Regex(COMICK_DOMAIN) &
        ~filters.Regex(gallery_dl_sites_pattern) &
        ~filters.Regex(PORNHUB_DOMAIN) &
        ~filters.Regex(EROME_DOMAIN) &
        ~filters.Regex(EPORNER_DOMAIN) &
        ~filters.Regex(XVIDEOS_DOMAIN)
    )
    application.add_handler(MessageHandler(general_link_filter, handle_link))
    video_sites_pattern = f"({PORNHUB_DOMAIN}|{EPORNER_DOMAIN}|{XVIDEOS_DOMAIN})"
    application.add_handler(MessageHandler(filters.TEXT & filters.Regex(video_sites_pattern), handle_pornhub_link)) 
    
    application.add_handler(CallbackQueryHandler(button_callback))

    logger.info("Ø±Ø¨Ø§Øª Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§Ø³Øª... (Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ Ctrl+C Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯)")
    application.run_polling()

if __name__ == "__main__":
    try:
        main()
    except (KeyboardInterrupt, SystemExit):
        logger.info("Ø±Ø¨Ø§Øª Ø®Ø§Ù…ÙˆØ´ Ø´Ø¯.")

